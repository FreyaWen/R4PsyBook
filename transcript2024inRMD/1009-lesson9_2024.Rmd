
editor_options: 
  markdown: 
    wrap: 72

# 以下是课堂语音转文字


大家晚上好
我们开始上课
呃
上节课我们介绍了开始使用r语言
呃
分析数据
然后呢是以我们最常见的
或者说我们心理学当中
最常见的两种方法
t test和Lobo对吧
但是我们把它归
就是给它加了一个标题
叫做肾型
就是回归模型或者肾型模型
一
然后我们再介绍完
如何使用r常规的啊代码
来实现这些功能
之后呢
我们又给大家就是讲解了一下
为什么t test和Lova
它实际上是摄影模型的特例对吧
那么这个是我们在呃
如果要运行我们阿妈当的话
一定要提前准备一下这个代码
然后我们上上节课呢
是以这个表结尾的对吧
也就是说我们常见的这个tea test
呃包括这个单样本
独立样本和配对样本的t test
以及单因素的呃
这个放射分析和多因素的放射分析
基本上都可以用r里面的
最基本的这个呃
space就是统计学的这个包
里面的LM ini model来实现
而且呢
我们也可以从这个线性模型的角度
对它进行解读
对吧比方说我们发现这个t test
它可能就是一个质变量
质变量是二分变量的一个回归模型
对吧然后还有其他的
那么我们在这里都有讲解
那么上节课呢给大家呃
在讲解的时候
我们用的是pangu那个数据对吧
然后呢在这里也可能会涉及到呃
对一些疑善变良的虚拟编码的问题
那么虚拟编码呃就是说对尼山变
量的这个虚拟编码大米扣顶
它其实有很多种方式呃
在这个space
这个这个这个包里面呢
它是专门有一个叫做control呃treatment
这样一个方式
来对呃我们的这个这个理想变量
怎么进入回购方式进行编码
有一个就是有各种各样的方式
大家如果感兴趣呢
可以去参考一些相关的资料
那么我们采用的时间就是一般啊啊
首先就是大家注意点
就是不同的软件或者不同软件包
它的默认的编码方式可能是不一样的
这里这里面可能会有一些区别
所以有可能比方说呃
由于这个默认的编码方式不一样
最后会导致一个结果就是呃
你看到的统计的结果是不一样的
在第八课呃
我们在课后呢做了一点点小的修改
就是我们不仅仅可以采用
比方说FX那个包来去呃
达到一模一样的一个呃
就做那个回归
应该是做放射分析的时候
我们可以然后采用多种方式
来实现跟放射分析一模一样的结果
对吧那么其中一个方式
就是改变他的这个control treatment
就是改变他这个编码方式
大家如果呃
把我们呃
那个那个最新的阿玛当拉下的话
可以去回回顾的话
看一下我们上节课的课件
那么在结果上面的话
这个treatment
我们的现在这种编码方式呢
就实际上就是以其中的一个条件对吧
比方说我们上节课呃
讲到了不同的这个气温带
那么我们实际上就是以热带作为基准
对吧就作为基线然
后
另外的这种回归系数
它分别其实表示的是另另外两种条件
跟它的一个差值
这里我们其实可以做一个呃
从这个这个统计数据上面
对吧能够看得出来
那这是我们上节课的一个结果
那么上节课呢
我们回答一个问题
就是说
对于这种有重复测量的这种情况
怎么办对吧
在我们心理学当中
另外一个非常常见的一个一个现象
或者说一个呃
使用的一个方法
就是用重复测量的方式分析
那比方说我们最常见的呃
说有一种比方说
我们要呃检验某一种干预对不对
某种心理干预也好
或者是药物干预也好
它有没有效果
那么一般我们会设计一个
就是干预前进行一次测量对吧
然后干预之后
然后再进行测量
然后不仅如此呢
我们可能还有这个叫什么
就是实验组
我们还有控制组对吧
那么我们有组件变量
我们有组内的变量
它就是前后侧对不对
那么对于这个前后侧的时候
它就涉及到了
一个重复测量的一个问题
那么所以呃
在我们心理学当中呢
尤其在实验研究当中
我们非常常用的
就是重复三两个方式分析
那么我们上节课既然讲到了
说t test和方程分析
对吧组建的这个方程分析
它是一个线性模型的话
那么我们再回这个重复生的方程分析
它是一个
它是不是也是一个呃线性模型呢
我们这个时候
就是以我们在课堂上
经常采用的另外一个例子
呃就是我们
那个实验的数据对吧
matching的这个数据为例
那么这个数据的话
它是一个典型的认知兴趣的实验
采用的是完全的被训练设计对吧
啊每一个我们有2*2的这个实验设计
也就是说我们有两种自变量
一个是这个刺激他的身份
另外一个是这个刺激他的一个呃
我们说可以认为他是道德上的校架
对吧
到底是积极的moral还是消极的in moral
然后那么这两个自变量的话
它就组合成为4个条件
那么每一个被试
他在实验当中
都要经历所有的4种条件处理
对吧那么我们通过之前学到这个呃
不如啥呃
然后用here这个包对吧
在我们的这个课件的所在文件夹内部
我们可以通过这种方式把它读取进来
读取进来之后的话
我们可以看一下
我们先做了一个处理啊
我们在实验设计上当中
我们是有两个自变量对吧
但是在我们的这个数据里面
我们当时呢
是用一个变量性来表示这两个自变量
对吧就是两个质变量的各种组合
那么我们这里呢
先把它进行了一个拆分
实际上
是用的这个TIDR里面的一个函数
这是数据预处理的部分
大家有可能啊
以后也会经常碰到这种制服的处理
TIDR里面有一些函数是比较方便的
然后处理完了之后呢
我们可以看到它这个数据
嗯每一个背式
然后有他的年龄性别
还有他的左右一手对吧
然后还有这个实验的信息
那么原来是一个呃一
个变量对吧
是就是这个试次
他是一个什么
呃他这个形状代表的是什么
我们拆分之后的话
它就拆分成了两个倍量对吧
一个叫做Venus
一个叫做identity
然后我们就发现
这个数据实际上是有很多的
每个倍数还有很多个试次对吧
那么这种情况的话
大家通常做法是怎么做呢
如果通常我们用常规的这个重复
再来帮助关系
大家怎么做呢
有基础心理学方向的同学是吧
我们有比方说有40多个倍数对吧
然后有四种条件
我们最后会算出每种条件下每个倍数
在每种条件下的这个
比方说我们关心反应时间的话
就是反应时间的一个均值对不对
那么最后我们得到
比方说
44个倍是他们的这个反应时间的均值
对不对
然后呢
我们就把它输入到SPS里面对吧
然后进行一个重复3秒放大分析
然后把它对应好对不对
这是我们常规的做法
那它数理结构基本上就是这样的对吧
每一个被式
然后呢有自我
有他人然后自我和他人下面的
又有moral和in moral两个条件
对吧Alt的也有moral和inmoral
这样的话
如果说我们在本科
见到我们甲方的分析的时候
我们就会告诉大家
这里面会进行方差的分解对不对
然后我们把它分分解为
不同条件之间的这个变异
或者不同的呃
这个自变量引起的变异对吧
以及这个贝氏
贝氏的个体差异
然后我们主要关注的
比方说就是这个自
变量它引起的这个变异
在总体的变异当中的这个
这个比值对吧
然后根据这个比值去计算f值
等等等等
计算MSE就是谁的对吧
这是本科的或大概考研的时候
可能会还记得的内容
会涉及到内容
那么在SPS里面
大家可能也看到过
类似的这个实现的方式
那么在呃r里面呢
也很方便的进行实现啊
那我们先按照常规的方式
来进行一个处理
对吧先进行一个预处理
呃
比方说我们一般看反应时间的时候
我们主要看的就是正确的反应
4次的反应时间对吧
那么这样的话
我们把这些没有反应的
和这个错误的都剔除掉
对吧
那么在这里我们还有一点额外处理
就是我们把这个match就
我们先还有一个条件
就是
这个图片和这个文字是不是匹配的
我们这个时候只关心呃
这个这个匹配的
因为我们上课做一个演示啊
简化一点
那么所以我们筛选出的是匹配的
这个事实的数据
然后呢因为我们关心反应时间
所以我们选出了全部为正确
事实的一个反应
那么然后我们就通过这个group i对吧
在process在数据运输里面
我们呃提到的这个函数
呃以贝式的ID
然后identity和这个value
三个作为分组变量
然后通过summarise去求他们的一个均值
对不对这都是我们前面学到的内容
然后这样的话
我们就得到了
我们非常熟悉的这种数据
但这个时候如果大家想要
把它输到SBS进行预处理的话呢
我们还要把它从长的
长型的数据转成宽型的数据
但是在r里面的话
我们其实没有必要转啊
就是
我们可以直接使用Blues r里面的这个m
LOGO然后把base的ID放进来
然后DV对吧
dependent variable等于RT
很方便
然后这个within就表示是within subject
嗯应该是independent variable
那么我们这里有两个对不对
就是identity awareness
那么到这里的话
其实整个r里面就输完了
我们这里只不过是把它的结果
后面这个部分的话是为了显示结果
所以前面的这个部分
就是大家可能会比较关心的
如果你自己在哪里面
你就选择这段代码音频的话
你会在那个呃阿妈杠里面就看到
直接看到他全部的输出
OK
那么我们看多少里面最重要的输出
或者我们最关心的输出的话
可能就是这个表对吧
放在分析表
那么这里面我们可以看到identity villains
它们分别的主效应
和它们的一个交互作用
这时候我们可以看到很明显的
这个就是
比方说这里有p值对吧
f值这是大家都很喜欢的
然后还有大家可能没有那么常用的
现在越来越推荐报告的
比方说这个e square
叫伊塔方对吧
反映的是呃这个效应量的一个指标
那么波尔达里面它有一个好处
就是它会输出多个这个效应量的指标
包括pashaidscript
偏伊塔方
包括叫杰诺来自伊的script
这是一个更加推荐的
一个效应量的指标
还有CONS f啊
这也是以前会有一些啊
做云飞系的时候
大家会用到的一些指标
那么从这这里顺便可以稍微多讲一句
就是当涉嫌涉及是Lova的时候
大家有的时候可能会想
我如何用它来规划量本量对吧
把什么作为一个效应量
输入到gpower里面
而这里要有一个非常小心的
值得注意的问题
就是大家如果是完全背室内的实验
设计的话
千万不要说我用gpower做的
做了这个样本量的规划或者powernatives
因为gpower做不了这个事情
如果你这个审稿
你的稿件里写这么一句的话
审稿人如果有经验的话
就一下看到
你可能就是表演了一下这个
呃这个这个方叫什么
power analysis
然后这是毒杀里面的输出啊
呃我们可以看到
毒杀
他实际上是对另外一个很方便的包
打了一个
就是在进行一个封装
就是FX呃
我们其实之前也见过这个包对吧
那么在赛词里面
我们可以得到同样的结果
这里我们就不再展示了
那么通常如果说我们啊
做这个方丈分析对吧
到这里我们接下来看到的交互作用
接下来就进行简单效益分析对吧
就像我们上节课结尾的时候
我们用Email去查看不同条件下
比方说在不同的这个identity条件下面
对吧不同awareness的效应
或者反过来
不同的awareness下面这个identity的效应
对不对我们这里就不展开了
这里就
是因为跟上节课是一模一样的
大家可以就借用比方说
上节课的一个代码
来做同样的事情
也是可以的
那么我们今天想要讲的就是说
从这个方面分析
它
可能对于做实验的同学来说非常熟悉
对吧在哪里面也非常简单实现
那它到底有没有
有没有问题
或者说是不是有更好的做法
以及为什么它是一个呃
我们可以认为
它是一个线索模型的一个特例
首先的话
我们看到的基本上就是这个
所有的效应都是叫做主水平的效应
对吧我们比较的是
如果大家去仔细回顾一下我们啊
这个方差分解的那个逻辑的话
我们会发现在整个方差分解的过程中
我们关注的都是不同条件下
主水平的一个均值
对吧每个数据点和这个均值的偏移
到底是什么样
就从这个角度来讲的话
我们会发现
我们是基本上完全忽略了
个体的差异的
在这个从不在的方式分析里面
当然在我们整个实验
在大部分的认知实验当中
我们也都是不太关注个体差异的
我们可能更多的关注的是这个效应
对吧
也就是不同条件之间的一个差异
然后另外的话啊
这个缺失值的处理呢
也是比较啊
他是非常严格的
比方说我们有四个条件对吧
就是2*2有四个条件
那么如果说我们有一个条件上
有一个缺失值的话
那整个背时的数据就没有
没办法再使用了
你如果采用的是
更加就是老一点的这个做法
比方说不管你是
用SKS还是用EZ
呃EZ这个耳包的话
当你的数据不平衡的时候
他直接就说我
他直接就没有办法出结果
会报错
那么你只有把那个有缺失值的
整个背时的数据完成删除掉
这样的话你的数据才能够运行
这样但是他会带来一个问题
就是说即便这个背时
他可能缺失了一个条件对吧
但他还有三个条件的数据
这三个条件数据其实也是有信息的
还有他会对这个数据类型对吧
有这个要求
比方说我们现在看到的是这个呃
自变量他是分类的条件对吧
假如说我们自变量是个连续的数据呢
对吧我们这个时候
就很难用这个中置像框的分析了
然后还有呢
我们对每一个贝市的这个整个数据
其实利用率是比较低的呃
怎么说呢
我们可以回过头来看一下
我们这个数据
对吧
我们在看到这个原始数据的时候
每个倍时
它在每个条形上都有很多个试次对吧
每个试次下面都会有自己的反应时间
但是
我们在做重复测量方的分析的时候呢
我们先把它求了一个均值对吧
我们用的是一个每个倍数
最后比方说它有60个票
60个四次对吧
或者70个四次
那最后我们就把它平均起来
当然你平均之后
每一个被试的
每一个试词的
有一定的信息可以用起来对吧
但是可能还有很多信息都被丢失掉了
这带来了一个呃
这个数据的一个浪费
事实的一个浪费
那么在脑电的这个数据当中
其实有的时候你需要权衡
你到底每一个倍数做多少次对吧
以及这个做多少人
你才能够比较有比较强的这个统计
简历把你关注的这个效应看得出来
那么这个在4次的每个背时做多少
4次对吧
和背时的人数之间的这个权衡
其实这两天关注的人也很多
包括前段时间我们在那个呃
open 30的公众号
邀请了新加坡国立大学的一个科里斯
他们介绍的就是在FMI中
你这个扫描的时间对吧
和你背时的数量之间
你如何达到一个平平衡
因为你真的扫iPhone 8扫描时间
你也能够提高这个数据的呃质量
或者说你这个信号的这个呃强度
所以这里会涉及到很多
这个如何充分使用这个数据的问题
以及提高我们的呃统计功效
对吧是在Disco
那么正是因为这个原因呢
其实这两年在一些期刊上面
我们也能够明显的看到
就是大家开始推荐使用呃
就是不再使用这个
不再完全依赖于t test和Lobo对吧
而是采用这个mixed model
比方就是混合线型模型
我们这里举的是new run在呃
这两年发的一篇
叫做Premier
就是一个一个呃
那是一个教程吧
呃就是两年之前的
再加上这个牛郎
是如果大家做成绩选项
偶尔会会就会发现就是牛郎
实际上
是我们整个整个神经科学领域啊
不仅仅包括认知神经科学
包括神经生物学领域
非常呃顶级的一个期刊
也说这种主流的期
刊也都开始推荐使用
这种更加合理的方式
那么这就是我们今天
要跟大家简单介绍一下的
这个多层线性模型
那么它实际上就是用来处理
这种多层嵌套类型的数据
我们之前说过对吧
我们的这个数据是有有嵌套的
整个实验的数据
对吧它是分成在一个一个背式
每一个背式下面又有不同的条件
每个条件下面又有不同的试次对吧
所以它是有这种嵌套的结构的
那么如果我们用长以前的这个方法呢
他就就就说是有一些信息的浪费对吧
呃所以现在很多人在推荐使用
这个层级模型
或者叫做分层模型
或者叫多层模型
那么它的名字非常多啊
比方说hierarchy model对吧
或者叫做hierarchical Mini model
或者叫做Multi level model
或者叫做这个name next model
等等等等
就是名字很多running effect model啊
大家知道
它本质上就是说
我们要去处理这种多层线性模型
对吧多层的这种数据结构
那么我们如何去考虑
层级之间的一个相互影响
另外呢我们就是比方说考虑这个呃
它的这个效应
在不同层级之间的一个变化
这个主要就是
呃这个多层线性模型
或者分子线性模型的一个核心
或者层级线性模型对吧
那么可能在有一些领域呢
它可能根据这个
多层面具模型的这种思路
它发展出了一些新的
特异于
处理某一些特定类型的数据的方法
那么
它还会给它一些叠加一些其他的名字
大家
最重要的就是你要看到它本质是什么
它是不是比方说用以线性模型
或是广义线性模型
广义线性模型我们家里会会讲
以线性模型作为最核心的一个模型
对吧
然后去考虑他的这个数据的层级结构
或层次结构
如果他有做这样做的话
基本上你就可以
他的原理上
可能就是跟我们这里讲的是差不多的
那这里跟多元回归是完全不一样
多元回归是说有多个自变量对吧
但他是没有考虑这个层级的
这个结构的
那么在这个呃
多层线型模型啊
或者层级线型模型当中呢
有两个很重要的概念
我们先给大家简单的说一下啊
因为我们这里的这个成绩模型
它都是以回归模型对吧
就是以正态分布为核心的
那么在这种现行的成绩模型当中呢
一般我们会考虑啊
从这个结具和协律对吧
就是这两个效应上面
去考虑我们这些效应
那么在沉积模型当中
它最关注两个效应是什么
就是就是固定效应和随机效应
这个名字啊
就是一个叫fix effect
一个叫random effect
这个所谓的固定和随机
他其实这个名字本身非常不好理解啊
那我这里呢也不不去
就是说跟大家
跟大家把这个里面的呃
就是做非常细致的展开啊
大家如果感兴趣的话
可以去看知乎上的一个博客啊
就是包含吴庄老师写的呃
那个博客
是对随机效应这个做了一个比较呃
比较详尽的一个梳理啊
那么我们就通过一个例子
来看来给大家展示一下
什么叫做固定效应和随机效应
那比方说
我们看一个非常简单的明
简单明了的一个层级数据
呃
这个比方说公民对吧
和薪和薪水
和和你的这个工资之间的一个关系
那比方说
我们想要调查
这个高校老师的这个工龄
和工资之间有没有关系
对吧那么从某一个学校里面
随机抽取出5个学院
对吧那么然后获得他们这个呃
这个工资和工龄
工作年龄之间的一个关系
对吧啊
这是一个网上的数据啊
呃这里有数据来源
大家如果拿到阿玛克丹的话
可以点击这个来源
然后这个数据结构大家可以看
它基本上是这么一个嵌套的结构对吧
首先你整个大学或者你整个学校对吧
然后它有不同的partners
它有不同的这个学院或者系
那么每个系下面有不同的人对不对
你调查的时候
实际上就是在不同的学院下面
去搜不同的人
对不对然后再去从这个每个人身上
找到两个数据
一个是他工作多少年
另外一个是他的这个工资对吧
然后你最后思想
你关心的是工资
和这个他的工作年限之间关系
那么如果我们不考虑
他的这个欠条结构的话
我们可能就把所有信息都放在一起
对不对
那就做一个总体上的一个呃
这个回归模型
然后做一个简单的现金回归
那么在这个情况之下
我们可以看到
XO就是我们的这个这个工作年龄对吧
然后y就是他的工资
那么
从这个角度讲的话
看起来似乎在工资和呃
工作能力之间是有一个微弱相关的
对吧但是我们这个时候
假如说把不同的department
把他们不同的这个呃学院对吧
把他们这个用不同的颜色标出来的话
我们可以看到这个线他到底捕捉的是
有没有捕捉到任何一个学员的信息
你看起来好像其实它跟表面上看
好像是跟
每一个跟跟就捕捉到了某种关系
对吧但你仔细看到
好像又跟
每个学院的这个模式都很不一样
在这个情况之下
我们就可以看到
就是假如我们不去区分
这个数据的成绩结构的话
我们最后得到的这个呃回归线对吧
或者说这个预测关系
它可能不太用
不太有用对吧
尤其是你拒绝到
尤其是我们已经有了学院的信息
这种情况之下
所以我们在这个地方
我们可以看到明显的两个问题对吧
第一个就是说大家的起点
当我们的工龄是0的时候对吧
大家起点其实是有区别的对不对
大家看不同的颜色区别是很大的
然后呢我们这个总的回归线
他的这个起点
好像就反映的是一个综合的
对吧
第二个就是不同的这个学院之间的话
工龄和这个工资的关系也是有差异的
对吧
再看看有的就是随着工龄的增加
它好像它是在上升的
有的好像你看不到一个明显的趋势
对吧比方说这个粉红色的
所以会不会
就是说我们要去做回归时
会不会有两个这种
这种运气间的差异是
完全没有考虑的一个
就是他们的底薪是不一样的
或者起薪是不一样的对吧
第二个
他们这个工资和工龄之间的关系
在学员之间是存在明显的差异的
我们不能够用一个总体的趋势
去捕捉到每个学院内部的工作年龄
和这个工资之间的关系
对吧那说明我们这个模型
可能就没有那么有用了
那么这样的话
上面两种可能性对吧
它就对着我们说的这个
4种不同的模型对吧
假如说你认为这个所有的不同的学院
对吧他的底薪是没有差异的
或者他起薪是没有差异的对吧
对于这个呃
对于这个这个回归线来说呢
它的这个起心
就类似于我们这里的这个
这个直线和和这个外轴的一个交界点
对吧就是我们的节距
你认为这个节距是在不同的呃
这个学员之间是没有变化的
你认为它是固定的
OK所以这就是叫做固定的结局对吧
然后假如说
你也认为这个公理和公制之间的关系
在不同学院之间
他都是以同样的速率来变化的
也就是说他们之间的关系
在不同的学院之间他也是固定的对吧
那么在我们的回归线上呢
他表现就是固定的旋律
那这样我们这个在这种
就相对是一个比较简单的回顾
当中这个线对吧
它的斜率代表是什么
就是x每增加一个单位
基本上对应的y要增加多少对吧
有时候协力越大的话
表示你们你的工龄每增加一个一年
那么工资增加的越
多对吧
所以这个协力
它表示我们这个回归线的协力表示
就是呃XY之间的一个关系对吧
也就是说在我们这个情况之下
当你认为在不同的学员之间
工资和工龄的关系
他是完全一模一样的时候
是固定的时候
那么这个时间你认为它的这个斜率
这个回归线的斜率也是被固定下来
对吧那么这种情况的话
它就称之为叫做固定结局
固定斜率的模型
所以就是我们的最开始的对吧
我们就不管这个学院了
把所有的数据放在一起
然后做一个简单的回归就完了
那么但是还有其他的可能性对吧
比方说我们认为他的这个结具对吧
也就是起心
在不同的学院之间是不一样的
但是呢他的
我们假定他可能每一个学院
他以他的这个工资的涨幅对吧
比如说随着你的这个工龄增加
你的工资增加的这个数率
他是一他是相同的
他在部分学员之间是保持一致的
那么就会出现这种情况对不对
每一个学院他的这个起心
他的起点是不一样的对吧
但是我们看这个斜线
他的斜率都是一模一样的
那么这个就叫做固定的结据
呃然后呢
随机的旋律
那么这个随机
大家可以看到
随机的意思就是说
你的这个旋律在不同的组之间
在你的这个群体当中不同的组之间
它是在变化的
在进行变化对吧
very并不说它是
但它并不一定是随机的在变动
OK所以为什么随机效应这个词很就是
刚开始让人很容易误解
他就是说我们这个效应
某一个特定效应
他在不同的组
在组成这个总体的
这个不同的组当中他是在变化的
那么我们现在看到的这个
就是这个起点
对吧这个直线的起点在不同学院
他是在变化的
如果说我们把这个在0这个地方对吧
我们画一条这个垂线的话
那么这个斜线和这个0外轴交接的话
那么这个交界点它就是在变化了
对不对
这就是我们说的这个变化的结句
intercept那么但是每变换年龄
每增加一个单位对吧
不是工作年龄
工
应该是工作年限啊
工作年限每增加一个单位
那么你工资的变化的幅度都
我们的回归线基本上都是一模一样
对吧这个时候我们看到
他其实也不一定能够捕捉到
每一个学员的特点
对不对
比方说我们还是看这个粉红的线的话
这个粉红线
它看起来更应该是一个平的对吧
而不是这个斜斜的一个增长的方式
但是因为我们在建这个模型的时候
我们没有让它进行变化
我们强制的让每一个学院
他的这个回归线的斜率
都是一模一样的
把它固定住了
那么这个时候
我们看到的就是这么一个礼盒的效果
那么还有一说就是说
我们认为这个底薪是相同的
但是工资的涨幅是不一样的对吧
那么这个就是叫做固定结局
随机协定的情况
那么最后的话就是说
我们认为这两个都是不同的
它的起薪也不一样
然后呢它的这个协
率也不一样
那么我们刚刚看到这个对吧
这个其实比较少见的啊
说在所有的人
他的这个固定的
他的结局是固定的
然后但是这个这个协力是不一样的
我们看这个其实很不符合现状是吧
那么最后一个的话
就是说这个ins up
这个slow结具和斜率
他他都是在变化的
那么这个时候
我们看到他的礼盒的效果
就是比较好的对吧
比方说我们看到这个粉红的线
它的起心就是可能比这个蓝色的要高
对吧但是呢
它一直没有什么太大的变化
蓝色的起心比较低对吧
但它可能一直在变化
所以我们通过这个情况的话
我们就能够捕捉到这个一个比较好的
这个特点
那么这个这几条线
这五条线
反映出来
就是我们的所说的这种叫做very effect
或者叫做变化的
或者叫做就是随机的效应
在有一些作者
有一些研究者
更加喜欢使用very effect
是变化的这个效应
而不是random effect
OK那我们现在再把这个四个图
给大家看一下
就这个时候都固定对吧
比如说所有的都是一模一样的
这个是斜率它是固定的
但是结句呢是变化的
所以呢
就是大家的这5条线是平行的对吧
但起点不一样
那么这个起点都是一样的
但旋律都不一样
这种情况
很少很少有人会去建这样的模型啊
那么这个情况就是两个都在变化
不管是结局还是斜率都在变化对吧
那这就是我们在混合线性模型里面经
常会碰到这个叫做这个呃随机效应
也就是在我们线性模型里面
呃在现有回归的模型里面
当我们做这种乘积模型的时候
我们有可能有两个
两个效应在变化
一个是intercept
一个是我们的这个呃slow
大家这个stop就对应着什么呢
就是我们自变量对应变量的影响对吧
如果说跟上节课进行关联的话
okay
大家有没有问题
OK
那么如果大家对刚才这两个概念
基本上清楚的话
我们就可以
因为刚才说
这个数据
仅仅是用来展示这个随机效应
对吧两种随机效应
那么对于我们的这个数据来说对吧
我们回到我们那个反义词的数据
那么我们这个数据
它其实也有一个嵌套关系对吧
就是说
每一个变量都嵌套在每一个背时当中
每一个背时
它自己可能就存在一个
类似于我们刚才观察的这个回归线
对吧
然后每一个背式
它的每一个条件下面还有很多个式式
对吧
每一个式式都是一个又是一个数据点
所以我们在我们这里的两种效益对吧
这个固定效益代表的就是
比方说
在总体上的不同条件下的一个差异
对吧
比方说在我们的这个match
这个实验当中
我们现在有两个自备量对吧
那么这两个自备量identity和villains
他们对反应时间的整体的影响
就是我们说的固定效应对不对
那么每个倍时身上
他的这个identity和villas
他的这个影响
可能跟总体的是有偏差的是
不一样的对吧
那么这个每个贝时身上
identity和value的影响
就是一个very effect
就是在变化的一个随机的效应对吧
那么它反映的就是说这种
不管是这个贝是个体差异也好
还是说这个贝是对identity和villain
是一种特异性的反应
也好
对吧它都在跟总体上面
identity和valance的效应
产生的这个偏差
那么这个偏差有可能是有意义的
对不对
那么这个时候
我们就能够把它通过这种沉积模型
把它捕捉到
我们可以看一下
对于我们nice的数据来说
每个背式对吧
他会每个背式都做一个数据
他下面嵌套了
比方说自我他人呃
然后自我和他人下面又嵌套了
这个moral和immoral
然后在这下面又嵌套了
比方说有60个式次或者50个式次对吧
下面又有50个式次
这下面有50个式次对吧
同样对其他倍式来说也是如此
那么他们这个数据类型的
这个嵌套的方式呢
其实我们也可以用这种
也可以把它就是跟这个screw对吧
跟我们刚刚看这个数据做一个类比
我们这里可能就是
可以在这里再加一个
对吧然后就是整体上面的一个效益
对不对
那么大家会觉得
我们好像就是说在平时
在实验当中
我们很少去看对吧
每个就是不同的这个实验处理
或者不同的制片量
在个体的这个身上是不是有差异
对不对
那么大
可以想象可能每一个贝氏
他自身的反应速度就会有很大的差异
对吧有的贝氏他他就是很快
他不管做什么反应都很快对吧
因为他的机械的反应是就是非常快的
那么另一些
他的反应就是整个就比较就比较慢
对吧
你不管是说这个自我的也是他人的
还是说摸耳语摸耳他都他都慢
那么这种就是反映的是
类似于像我们这个什么
结句上的一个差别
对吧你这里打错了一个字啊
这应该是随机的结句
那也就是说
他的总体机械就会比别人更快一点
或者更慢一点
我们在这里展示的4个呃
4个贝时的数据
大家可以看到
像这个贝时的话
我们他的这个反应时间
整体上面就会比其他的要低
对吧
当他每一个事实上面可能会有快有慢
但是整体上的话
这个倍数他就会比这个倍数对吧
他就快很多是不是
这个就是我们说的这个
在反应时间上面
就可能存在这样的一个随机的结局
对吧一些被子
他平均的反应时间
他就会要更快一点或者更慢一点
那么另外一个呢
比方说我们刚才说到
我们这个实验有两种效率
有两个自给量对吧
一个是violence
一个是identity
那我们就在这里举一个例子对吧
就比方说在这个自我条件下面
那么violence
两种不同的violence
它的差异是不是相同的
那么你昨天讲的话我们再看
我们再看这个
比方说这个呃
从这样方法分析的简单效率的时候
我们也是这么做的
对吧我们看到这个自我条件下面
比方说mol和in
MO它之间的差异是多少对吧
我们最后
还甚至可以把它量化出一个cost
那么这个时候我们量化设置cost
两种在自我条件下
这两种不同条件的
这个差异就是什么呀
就是我们通常所说的这个face effect
对吧固定的效益
但是即便我们通过从这样方式飞行
我们能够把这个固定效益算出来对吧
那么每一个背式
它之间的这个差异
我们是完全不知道的
那有没有差异呢
我们其实可以可以看到
是有很明显的差异对吧
我们这里画的是在自我条件下
也就是说在他人条件下
所有他人条件下的这个数据
我们都没看
我们只看到自我条件下面的这个
Molo和Inmolo
他们之间有没有差异
那我们可以看到
对于这个倍是70呃7307来说的话
大家可以看到
这个moral比immoral要快一点
对吧
就是大家可以看到
这个斜线是有点从左往右
是往往下对吧
那么7311这个倍数来说
那就是更明显了对吧
它的moral是比inmoral要快的
那么对于7313这个倍数来说呢
它就是呈现了一个相反的趋势对吧
那么对于73224这个杯型来说呢
它也呈现了一个相相反的一个
一个趋势
就是这个moral要比moral要更快
那么整体上面的话
我们可能有更多的背式
是表现出了右边这两个背式的
这个情况就是model比in mode要更快
所以呢整体上面我们可能会发现这
个model会比in mode它的反应时间是呃
更短的
但是我们可以很明显的看到
这种背诗的个体差异
对吧那么这个也是呃
我们可能后面在这个PPT上加上
就是在JPG有一篇
2021年左右有一篇文章
就是专门强调
我们需要去考虑
实验处理的这个抑制性
这里我们很明显就看到了
这个实验处理的抑制性
对吧就是不同的背时线上
它这个实验处理的效率是不一样的
我们以往是完全不关心它的
但是我们其实是需要关心它
如果我们认为我们的这个测量的工具
或者我们的认知的这个任务是一个
就是某种程度上
能够对背视的
内在的一些不可观测的一些认知能力
对吧进行测量的话
那么我们应该关注这些个体差异
行我们先休息一下
然后接下来我们再再讲这个线性模型
如何来去建模型
以及如何解剖
好呃
咱们继续
呃我们刚才就是说讲呃
通过这个对原始数据的可视化
对吧我们发现
呃首先呢
比方说这个原始数据有很多个数据点
对吧第二个
就是它可能会存在这个随机的结句
和随机的弦律
两种情况
对吧
比如说每个背时身上他的这种效应
呃在反义时上面
他的这个效应是会存在变化的
那么假如说我们确实发现有这个问题
那么我们要怎么去呃
用更现在更大
大家更推荐的这个做法去实现它呢
呃实际上在过去的大概十多年啊
就是这个
就围绕线性模型或
者叫做和残疾模型
这一类的方法的话
开发出了很多这种系列的包
那么像呃m e four
那么这个包的话
应该算是算是目前使用的最火的一个
使用最广泛的一个包吧
至少是最广泛之一
那么它的这个语句的话
如果光看这个语句的话
其实是很简单的
呃首先就是这个这个包的名字对吧
然后呃
做这个沉积模型的这个函数就是M12
然后后面就输入代码数据
数据然后呢
就是这个format对吧
这个format实际上是跟我们的这个呃
线性模型呢
是类似的
那么有的时候
我们可以甚至都可以直接把这个呃
formula如果你按照顺序的话
可以把这个formula就直接不用写对吧
它也能够识别出来
然后这个公式里面
跟之前的线形模型是类似的
就是前面这个波浪号
前面是dependent VERB对吧
呃inbinl然后后面的话
首先就是它分成两个部分啊
它这个公式分两个部分
一部分就是呃括号括起来的
另外另外一只括号之外的
括号之外的
就是
我们跟以前的这个线型模型是一样的
对吧也就是我们以前的
以前的这个线型模型
它就是只关注了fix effect
再回想我们刚才讲四种
四个可能的模型的时候
对吧你这个固定的结具
固定的弦
它实际上就是我们传统的
这个简单的回归
对吧那么所以我们剪这个固定的效
固定的这个因子啊
或者固定效应的这些变量
就放在括号外面
那么随机的
这个结局和随机的弦的话
就放到这里
那么这个地方
running FACTS
就是我们这里说的一个分组变量
比方说
你要用什么来对这个数进行分组
对吧然后看它的这个呃
每个组上有不同的这些效应
那么一般随机的这个run the minis up
随机的结句的话
我们用一
然后就跟我们前面写的这个回归
那个时间也是一样的
然后随机的这个协律的话
就是加上你这个呃
字本上的名字就可以了
那么当我们这是
可能是很多同学
第一次接触这个呃模型
这个称叫什么
分层模型对吧
呃
也是第一次接触这个随机效应和呃
固定效应
那么大家可能就可能还很难去说
很难去思考我们到底应该怎么去加
等等等等
但是呢
我们在这里还是先跟大家说一下
就是实际上这个模型的建立对吧
你把什么样的这个变量
纳入到这个呃
随机的效应之中
实际上是需要你思考的
首先你需需要仔细的去去想一想
他到底有没有这种可能性对吧
也就是说你要有充足的理由
那么一般来说
大家可能会都会加这个随机的结句
那么随机的协律的加入的话
呃目前啊就是实际上是有有争论的
至少我看到的一些呃这个文章的话
它是有争论的
然后另外的话
随机效应的话
一般就是说
是从总体中的一些理想单位
它是一个本质上是一个分类的变量
那么关于这个
真的啊就刚刚说的这个什么
应不应该把所有不
要说所有的资料都加到随机旋律里面
对吧
那么现在有不同的不同的研究者
是有不同的看法的
当然
大家可能目前来说可以暂时不用管他
后面你仔细对这个成绩模型
越来越熟悉之后
再可以去考虑这些点
这些比较比较细致的一些知识点
OK
刚才说的是在r里面用l me four这个包
去建
这个分层模型的一个基本语法结构
对吧那么在我们这里
我们可以把数据带入进来
数据的话就是我们刚才说的这个呃
原始的数据
然后前面是RT对吧
这里呢就是我们有两个自变量
一个是identity
一个是balance
然后我们这里大家可以看到
这里有一个加号
后面就是加了一个随机的啊
效应对吧
那么随机效应这个竖线对吧
竖线的左边就是你要你的公式是什么
你要你要让这个让哪些效应让它
就是说呃
有这个变化
那么右边呢
就是你的这个随机变化的这个
你这个变化的效益对吧
是随着是在哪一些组织间
是以什么样的标准进行分组
然后让他进行变化
在我们这里的话就是表示
就是说每个倍是他的一个
所以他的这个结局是不一样的
那么换成更普通更容易懂的话说
就是我们刚才说的每个贝斯
他可能对他的这个基本的
这个反应时间
对吧他是有快有慢的
那么当我们建了这么一个模型之后
相当于是我们
就是说它代表我们可能认为
那么identity of Vanance这个效
应我们肯定是在主水平上面
我们肯定是要检验的对吧
但是呢我们并没有检验
它在每个个体上的一个差异
有时候我们认为identity和Venus
它在每个贝斯身上的效应
跟总体上都是类似的
有点快啊
当然我们也可以把
就是这个identity和Venus
他们这个就是认为
它在不同的倍式之间是有变化的
对吧
所以我们跟刚才的这个相比的话
大家可以看到我们这个公式的变化
就是在这个括号里面对吧
把这个identity和Vanus都加进来了
那么这个乘号对吧
一个星号
呃一般在r表示乘号对吧
那么它实际上就是表示
是说两个变量之间
所有可能的一个组合
对吧然后adan点乘以这个valance
它实际上是表示了
identity的一个主效应
加上Vans的一个主效应
再加上它们之间的一个交互作用
那么交互作用的话是用冒号来表示的
目前的话这种写法啊就是这种表示
在在现行模型里面
这个量之间
就是我用一个长号
表示他们之间所有可能的这种呃
组合那么这是个很常见的一个写法
在r和Python里面
现在都已经
我觉得好像
至少我所观测到的这个主流的方法
都已经采用这种方式了
那么在这个随机的这个模型里面
我们这个地方一对吧表示
就是有固有一个随机的结句
那么有的时候我们也可以
比方说
我们认为他没有这个随机的结句
我们把它固定下来
这个时候你一
定要写上0
就是你要0加上什么什么什么
大家可以看到
我们在写这个固定效应的时候
我们没有写一加上identity乘以valance
对吧那么是因为在我们r里面
它默认的就有一个一加什么什么什么
在这个在这随机的这个项目里面的话
我们必须得写出来
也就是说
如果我们认为他没有一个随机的结局
我们也得写出来
突然那天
假如说我们在前面的这个
这个公式里面
如果我们没有认为他没有结局的话
我们也也也可以就写0加上什么什么
这个都这个公式基本上都通用的
当然就随着这个模型越来越复杂对吧
呃后面大家如果感兴趣的话
可以专门去查一下这个公式的
这个里面很多其他的符号的一些写法
对于我们心理学员来说
最常用的可能就是我这里解释的
就这个长号对吧
还有他们之间交互作用冒号
还有这个竖线表示的
一个括号里面加竖线
表示这个随机的效应
那么假如说我们就用现在的这个数据
对吧
啊建了两个模型
一个是随机结局
呃随机结局
一个是随机斜率
另外一个是随机结局
然后固定斜率对吧
那么这个时候就存在一个问题了
这两个数据
这两个模型可能都能跑出来对吧
那我们到底要
要看哪一个结果
对吧这实际上也是
当我们采用这个沉积模型的时候
或者当我们把线性的这个回归模型
当作一种模型来处理的时候
我们会发现它的结
果
远远比我们在心系统计学上学到的
t检验放大分析
以及放大分析之后的这个呃
这个这一系列的分析要更加复杂对吧
因为首先它的模型就可能有很多个
比方说我们看大家还能够想到
在这种情况之下
我们还能有什么样的变化
大家可以看到
我们这里标注的这个公式
对吧RT它是identity
然后这个这个是identity的成语village
对吧
假如说
我们不变这个固定效应的这个部分
那么对于学习效应的部分
我们还可以进行变化吗
大家想一下
我们这里可能给出一个很全面的
一个随机效应对吧
大家看他还能继续变化吗
我们可不可以拿掉其中一个比方说
哦就把这个villains拿掉对吧
就是变成随机
随机下里面就变成e
加上identity
可不可以
也也是可以的
至少是可以运行的对吧
然后或者我把它把这个identity拿掉
是牛villance
我只认为在威尼斯这个制备量上面
不同的贝斯之间的这个
在威尼斯不同条件之间的这个效应
它是有差异的
在单体上我认为它是一模一样的
这也是可行的对吧
或者我认为他们俩有这个
两个主线都在对吧
但是没有交互作用
这也是可行的对吧
所以我们可以一下就可以就发现
我们可以建好几个模型
对吧那么这些模型
有的时候我们可能先要想清楚
到底哪个模型是make sense的
是合理的对吧
因为有些模型可能你凭你的这
个研究的经验对吧
你可以很明显的发现它是不合理的
你就不应该用这个数据去建这个模型
当你进来之后
他你把这个模型建起来之后
你在这个啊里面可以可以跑对
他也会给你结果对吧
但这个结果对你来说
可能是没有意义的
这个时候你可以
也就是说你需要用你的知识
你的专家经验和知识
去筛选哪些模型是合理的
是值得去把它跑出来的
去test的对吧
然后
当你觉得好像这几个模型都差不多
然后呢我需要通过这个数据本身
他来告诉我哪一个模型是更加合适的
对吧那么这种情况之下
我们可能就要借助一些
模型比较的方法
那么
我们可以直接对这些模型进行比较
对吧
哪些模型它能够更好的这个模拟
或者更好的拟合这个数据对吧
这个模型他他更符合
他更能够捕捉到
这个数据内部的一些特点
对吧
那么
就这就涉及到一个模型比较的问题
那么实际上模型比较的这个
这个问题的话
它基本上是在所有的这个统计学中
都会涉及到的
我当我们用沉积模型的时候
我们可能也会用这个模型比较的方法
去选择模型
那么在这个认知计算界模里面
我们也会用这个模型比较的方法
去选择在这个SEM里面对吧
这个方式模型里面
我们也有很多这种模型选择的标准
如果大家仔细去看这个呃输出的话
mplus或者是呃
这个SPS或者mouse里面输出的话
你也是可以
你也需要对不同的模型进行比较的
那么在我们这个沉积模型里面
比方说我们这里简单的展示就是用呃
space Lobo的这个呃
这个函数比较两个模型对吧
我们刚才是建了两个模型
一个是叫基本的模型对吧
它就只有一个random incept
然后另外一个就是它有
不仅有random incept
它还有所有的
这个叫run slope对吧
所有的这个随机的呃斜率
那么我们通过呃
当然如果你自己在那里面看结果的话
直接用输前面这部分就可以了
我们这里是把它给打出来
我们可以看到它会给一个输出对吧
那么这个地方
大家可以看到
这个地方就是他一系列的这个模型啊
这个比较的一个指标
那么这里就有两个模型对吧
一个是model
一个是model full对吧
然后这个m pair表示
就是它的parameters的数量
对吧然后我们可以看到
这个简单的模型里面只有6个对吧
然后这个负里面有16个模型
然后1016个参数
好这个就是AIC一个模型比较的指标
然后这个是BIC一个模型的指标
这个是not likelyhood
这是呃defense
然后还有就是对他的这个模型比较
指标之间
我们做一个检验对吧
用卡方做一个检验
那么然后就发现他俩之间的这个差异
本身就是模型的礼盒的程度差异
上面是虽然差异的对吧
而且呢
如果我们按照卡方的这个标准的话
发现他是显著的
那么这个时候我们就可以推断说
呃
这个后面的这个跟有随机截据和呃
随机协定
这个模型
是更加对这个数据拟合的更加好的
那么我们可能就会选择他
作为我们的这个接下来呃
解读的一个一个对象
对吧
那这里有呃
有一篇这个preprent的文章啊
就是呃两个呃年轻的博士生啊
这个跟我一起写的
我是主要是跟他们学习
然后大家感兴趣可以去看一下
然后我们基本上在这里的话
就相当于说我们已经做了呃这个
我们在从太阳花的分析基础之上对吧
我们又去做了一个成绩模型
然后呢
并且假定我们做了几个可能的
潜在可能的模型
对吧我们都对他进行了一个礼盒
然后呢我们再进行一个选择对吧
通过这个LOGO进行选择
选择完了之后
我们最后要对这个模型的输出
进行解读
对吧那么去看
我们最终感兴趣的这个效应是不是呃
就是
然后感兴趣的这个自变量的这个效率
对吧它在主水平是不是存在
那么在这个在这个呃个体层面
它是不是有很大的一个变异对吧
或者这个变异到底有多大啊
我们应该如何去解释解释这个变异
对吧所以
我们要去对这个结果进行一个解读
那么我们怎么去查看这个结果呢
比方说我们可以有一种做法
就是我们先假如说
我们对这个固定效应感兴趣对吧
就是
这里肯定要涉及到一个模型
比较的事项
就假如说我们要要去呃这个
看一下这个固定下
去他是不是显著的
那么我们怎么才能显著呢
一种方面就是说
我们可以通过刚才LOGO的这种模型
比较的方式
对吧
去对两个模型进行比较
一个模型是没有固定效应的
一个模型是有固定效应的对吧
它两这两个模型之间的差异就是
一个有固定效应
一个没有固定黑
如果说这个有固定效应的这个模型
要比没有固定效应的这个模型
要显出的更好的话
那它可能就说明了一个问题
就是这些固定的效应
它就应该放到这个模型里面对吧
我们可以认为它是显著的
所以这种失误的话
我们就可以先
我们就需要借一个极限的一个条件
对吧就是没有固定相应的一个模型
我们作为一个极限
然后我们刚才的这个呃
已经跑完的这个对吧
有固定效应
然后也有那个呃
随机效应的这个模型呢
把它和这个空的只只有随机模型
没有固定效应这个模型进行比较
我们比较完了之后呢
发现这个有随机的
不是有固定效应的模型
确实会更好对吧
所以这基本上就可以帮助我们判断
就是
我们加入进来的这些固定的效益
就是identity和business
以及他们之间交互作用对吧
他们肯定是呃这个呃有作用的
然后我们也可以用这个FX
FX这个包我们经常介绍它对吧
我们也可以用它的这个mix的这个呃
函数来进行检验
我们比方说就直接用他的这个mix
对吧然后把这个数据输入
进来然后呢这个地方呢
也可以看到呃这个地方呢
回归的方程是吧
跟我们刚才这个Internet model里面
在在这个多层模型里面
呃应该是在me four里面是一模一样的
对吧
也就是说我们是用在FX这个模型里面
我们建了一个多层的模型
然后呢通过这个呃
它里面的这个算法叫做RT对吧
来进行一个呃检验
那么这个时候它输出的结果呢
就是
实际上就跟我们传统的这个呃
方程分析
就很像对吧
它就会给出我们这个主效应
大家可以看到
然后还有交互作用
OK那么所以我们如果说
只想查看主教育的话
对吧我们也可以用这个FX这种方式
来去查看这个它的一个呃
固定效应啊
刚才应该是
如果我们是对固定效应感兴趣的话
我们也可以用f x mix的函数呢
去查看它的这个固定效应
然后第三个方法呢
就是我们我们可以用叫做M1 test
那么这个包
那么这个包的话
是跟ME four是兼容的一个包
它主要就是对这个混合效应模型
或叫沉积模型进行一个假设检验
那么它这里面就包含了一个函数
就是LMER
这个LMER跟这个跟这个LME four里面对吧
跟我们前面用到的
基本上名字都是一样的
就是不同的包
那么它的一个主要特点就是
它会报告这个显著性
那么它在这里的话
使用的是有它自己的一些算法啊
那么大家可以看到
我们用这个am压test的这
这个am压的这个函数的时候呢
嗯
里面的这个语法的输入
跟我们在AME four里面
基本上是一模一样的对吧
然后呢
我们可以通过summary来去看它的结果
哎这里是本来就没有叔叔啊
然后我们可以看到看到这里面的这个
呃如果通过summer的话
应该可以看到它的这个结果啊
呃
我们第一个看到
就是说它的一个随机效应的一个呃
相关举证
那么这个地方的话
就是
实际上就是要关注主要是这个地方
对吧
就是说
不同的随机效应之间
他们有没有一个相关性
但绝大部分的时候
我们可能啊不会太关注这些信息啊
嗯
然后我们可能更多的
更多的看的是两个
第一个就是把这个固定效应对吧
呃
就是类似看到我们的这个字字字面呢
和他的两个制备单
有没有主效应和交互作用
这个是我们通常会看的
然后另外一个
我们有的时候也会去专门看
他的这个变化的随机效应啊
这里我们可能没有展示
比如说在这个模式里面
我们应该是可以把比方说这个呃
identity对吧
呃或者是这个business每一个背时
在这个identity上面效应把它提取出来
然后看它在背时间是怎样一个变化
以及比方说millis的效应
或者他们之间的交互作用
然后的话
我们也可以对他进行一个可视化呀
那么这个可视化
是一个非常简单的可视化
呃这个固定效应的
呃
就是
我们这里全都采用的是默认
只要比方说他的这个顺序就是呃
他人和自我
对吧
然后道德的话也是以默认和默认
跟我们前面的城市呈现的顺序不一样
那么我们在讲完了这个统计模型之后
我们会专门讲呃
怎么在g Pro里面
去对这种最后要呈现的结果
进行一个精细的打磨
那么实际上在现在有很多包啊
包括像有像interact这样的包对吧
它能够帮助我们去迅速的把这个呃
一些我们关注的效应
能够快速进行可视化
让我们看到
它们之间是一个什么样的一个情况
比方说我们这里可以看到
这里是有一个很明显的一个交互作用
对吧
在这个r的这个条件之下
那么immoral和moral的差别
它肯定是要比在自我条件下
这个差别是要小的对吧
所以在这里
我们可以非常明显的看到
这么一个交互作用的存在
然后我们再看再看一下啊
就是呃我们前面讲
这个不同模型之间是等价的
对吧
然后我们也说从不测量方差分析
它是一个特定的一个呃
这个混合陷阱模型对吧
那么他们到底能不能做到
就是说呃完全等价
或者说几乎是相同的呢呃
大家觉得能做到吗
我们可以先看一看对吧
然后我们这里直接把之前的这个
从国家发射会的结果打印出来
我们可以
我们可以仔细看一下它的这个值
然后对Vincent来说
它的这个呃效益是f值是64.37对吧
然后p值是
很小的然后另外一个f值是
呃 14.36
然后还有这个adenty
它的这个f值是
呃 2.2.55对吧
然后这个DF呢
呃这个地方是143对吧
呃都是143
那么这个是跟我们呃
在心理统计学上学到的
这个重复测量分析方
呃重复测量方式分析是很像的
那么我们可以看一下m e four对吧
我们刚才建了好多个模型
然后我们选出最合适的一个
那么我们看一下
最合适这个是不是跟我们的呃
这个呃从质量方式分析是一样的呢
假如说我们直直接看的话呢
我们用这个Lobo这个函数对吧
把这个full model
呃把它的这个方差飞机表打出来
我们就会看到它的这个f值
呃有3个f值的
identity的是0.74
然后跟我们的2.55就不一样对吧
第二个是45点多对吧
然后跟我们的60多也不太一样
然后第三个也不太一样
但总体趋势都是差不多对吧
总体趋势就是identity很小
然后VN是比较大
然后它们交互作用也也比较大
那么我们再换看一下这个MLE
呃MLER test它的这个full model对吧
我们因为它是可以给出显示性的
那么它会不会得到呃
内饰结果
我们可以看到它跟m
e four得到是一样的
对吧呃
内饰的也不是一样的
内饰的这个结果
但是模式也都是一样的对吧
第一个f特别小
然后valance的比较大
Adam和valance的就会呃取中间
然后最后
两个都是呃
下面两个都是显著的对吧
所以我们发现其实好像不太一样对吧
因为这个从生态发射分析和呃
这个沉积模型的
我们常规的这个沉积模型的方式
是不太一样的
然后这个
其实我刚开始也是非常后悔啊
就是后来也找了很多这个呃
很多这个解决的方案
那么后来发现
他是要以一种很特定的方式
去建构这个
呃见过这个曾经模型
你才可能达到跟他呃很一致的结果
那么
我们这里啊
呃因为我们今年
是一直采用这个matching day的
就是这个matching数据的一个数
呃那个反应式的数据
然后呢
我们用它来去跟前面进行对比啊
然后我们呃还是
这个时候大家可以看到这里啊
我们用的是呃MT min对吧
就表示我们是用它的这个
我们在数据上面做到的一模一样
前面这里还其实还有个问题啊
就他们的数据是不太一样的
大家还有印象吗
我刚刚问
刚刚问忘记问大家了
其实我在这里就应该问一下大家
比如这里的MTV对吧
他用的是一个原始的数据
应不应该在这里
应不应该使用
对吧因为我们这个数据量很大呀
所以你们有一些没有清理的数据
他不影响这个整体的趋势
但是大家可以
假如你自己要做数据分析的话
这个数据一处理
这个地方肯定是要再考虑考虑的
然后回到我们这里
那么当然这里我们其实试过了
就假如说我们用一模一样的数据也是
用MTM来做这个从曾经模型
它得到的结果也也是不一样的
跟这里是同样的一个趋势
那么假如我们
采用MTM对吧
然后呢
采用这种方式去去建立这个模型的话
呃他可能他采用
应该说是最有可能得到
跟我们从这辆发动车
一模一样的结果了
那么这里呢
它这个模型是比较特别的
首先它有这个identity
Vanish的一个主效应
然后呢它有一个被试间的一个呃
一个random intercept
然后呢它也需要把这个identity和
就是identity和这个subject之间的这种
你可以认为就是每一每一个贝是在每
除了就相当于说除了每个贝
是有个整体的run intercept one
还有另外一个run intercept
就是每一个背式
在每一个identity下面
它会有一个独独特的
它会有个独特的一个intercept
同样对于每个背式来说
它它在每一个Vintage上面
也有一个很独特的
一个
一个这个呃random intercept
那么在这种情况之下
我们得到的结果是最接近的
然后这是59.89对吧
接近60 然后这个是15点呃36
然后可以看一下
跟我们这个60
呃64.3 七十四点 36是最接近的
但是他还是没有达到一模一样
那么我我也专门去
而且呢还有个问题
就是大家可以看他的这个DF
他的这个就呃这个
这个嗯自由度对吧
第一个自由度是一模一样的
然后呢所以说他的这个地方啊
达到了一样的这个值对吧
一是3和嗯
2.52.55 这个地方也是2.55
呃
这个地方也是2.5
但后面两个的话
他的自由度不一样啊
f值也不一样
那么如果我们仔细去
如果大家有兴趣仔细去把这个
为什么会出现这个问题的话
实际上就是因为
其实做两个
使用的两个不同函数的人
他们是有不同的习惯的
和不同的这个呃
或者说呃有不同的重视的点
那么对于呃
这个传统的从生产方式分析的人来说
就很注重这个
我如何对这个方向进行分解对吧
然后如何来去求这个f值
所以这一方面他们会做的很精细
那么不同的包之间的话
他其实也是能够达到精确的一致性的
但是对于LME的话
绝大部分使用LME的这个函数的人
他都是从做设计模型的角度
他不会去说我把这个模型做完之后
我再去做一个放大分析
然后看他跟这个重复生产
放大分析是一模一样的结果
那么在这种情况之下呢
我们就发现
他相对这个借助的计算的这个方法
他就是没有优化的
也就是说
像现在这个LME LME r test LME r这个包
或者LME four它它这里面
它更多的是去建现行的模型
而不是说
我如何把这个现行模型的结果
最后转化成为一个
以传统意义上的方式分析
因为这个转换的过程
大家可以想象
这个模型是本身比较复杂的对吧
所以如果你要让这个模型的转换
得到一模一样的数值上的结果的话呢
你其实需要做很多
这种就是软件工
程的工作了
你要写很多代码
然后把各种条件加上判断
然后就达到一致的结果
那么从我目前找到的资料看呢
就是很少有人在
就是很少有MFO
或者这一类用线型模型的开发者
会在意这个问题
就说我一定要把它转化的跟传统的
从这辆发展分析
结果一模一样
所以这一代呢
没有人去写
那么这个跟我们去年上课的时候呢
结果也不太一样
因为去年上课的时候
我们写了这个代码之后呢
他其实能够得到跟重复这样方的分析
基本上一样的结果
只差在只在小吃店后面有差别
那这里还有一个可能
就是说我们的这个模型本身
他可能会有一些warning
会有一些警告
如果大家跑自己在电脑跑的时候
他会会有一些warnings的
就是呃有个叫做segnality的一个问题吧
这里我就不展开了
这是属于模型这个
最后你和求解的时候的一个问题
那么也就是说
因为我们这个数据存在这个问题
所以最后我们直接用这个方法的时候
他可能就没有办法得到跟呃
从这两方的分析结果
在数字上一模一样的结果
在原理上面
在原理上面叫做原
或者说原则上
对吧
这个公式
它应该是跟我们从正常发展
分析是一样的
但数字上面
确实可能会出现不一样的结果
OK那么在这里我稍微总结一下
就是借这个公这个公式
也就是说我们呃
在心理统计学上学到的常用统计方法
对吧包括我们上节课讲
到t test和方程分析
它是线性模型的一个特例
那么我们传统上意义
我们传统意义上用到的这个重复三角
方程分析
它也是另外一个特例
那么它就是一个
就嵌套结构的
这种沉积模型的一个特例
对吧
那么在你的数据和你求解的方法
各方面
如果你能够比较理想的状况下的话
应该是能够得到一模一样的结果的
然后呢就是说呃
我们在这里看这个me for的结果的时候
它是比较丰富的
那么大家也可以找一些更加最先进
开发的包
去看能不能呃
更好的帮助我们查看这个模型的结果
为什么呢
因为呃这个模型的结果建出来之后
就比方说这个
我们这里看到这个model four对吧
这个文件本身是很大的
它里面包含了很多的信息
我们要就是
肯定有很多信息
都是可以直接去提取出来的
我们这里讲到的
最只是说最简单的一个
是这个fix effect
对吧
就是把如何把它这里面的这个呃
固定的项提取出来
但是我们在前面讲到
就是说这个随机的效应对不对
其实有的时候很很关键
那么其实它也是可以被被踢出来的
我们这里没有没有细讲
主要是时间不太够
那么另外一个呢
我们需要说明的就是这个呃沉积模型
它是一个很复杂的一个大的框架
那么
我们仅仅是以从生长方式分析为例
对吧
以我们这个常用的这个反应时间
这种非常特定的这种嵌套结构的这个
数据来介绍了这个沉积模型
但是我们其实有很多这种看到的
这个数据分析
都是在这个框架之下的
那么它可以适合很多
这种具有嵌套和层级结构的
这个数据的
那这里是举了几个
这个嵌套结构的例子
对吧然后缘分线
它其实也是一个特例
刘飞大家可能听说过对吧
你看某一个领域的这个
这个文献的时候
你肯定会讲哎
那我这里面有有没有人分析告诉我
这个这个效应
它的效应总体上是多大
那么实际上它本质上也是一个
也是一个这个层级模型
那么它这个成绩模型的话
比方说最高的就是我们总体的效应
对吧然后就是不同的不同的研究
不同的实验对吧
甚至可以我们再给加1+1层对吧
比方说不同的课题组或者不同的文章
不同文章里面有不同的实验
不同的不同实验项目有不同条件对吧
所以他也是这么一层一层一层的
这个牵扯下的
当我们做云飞机的时候呢
我们其实是建了一个特定的一个啊
这个这个沉积模型
我们用的是这种everyday的对吧
就是用的这种描述性的统计的数据
而没有用原始数据
那么有原始数据的时候
其实我们可以把原始数据
把所有
把所有实验室的原始数据拿到一起
对吧直接用一个大的沉积模型
把它进行一个呃效应量的综合
这也是可以的
那么这个是比方说大家在看猿飞机时
经常会看到这么一个这么一个图对吧
这个森林图不
同的效应
它之间呃从小到大进行排列对吧
它最后会出现一个什么样的结果
然后针对这个呃
原本性的这个结果对吧
检查他的抑制性啊
等等等等各方面的对吧
还有做什么原回归啊
很多很多这样的一些内设统计方法
但他本质上讲
他也就是我们今天讲的
这个沉积模型里面的
一个非常特殊的一个例子
那么我们在使用成语模式的时候
可能会碰到很多问题
我们今天讲的
是一个非常简单的一个入门
但是
我们这个部门也经常告诉回应了
我们前面在讲为什么学习爱运的时候
就是说当我们学习到爱运之后
我们可以开始使用
这些比较复杂的模型
那么
它会引出我们更多值得学习的东西
那么同样如此
对于这个沉积模型来说
当我们开始使用沉积模型之后
那么我们就会碰到很多
这种可能存在的问题
这些问题就会让我们进行进一步的
去学习
这个沉积模型里面的一些技术细节
比方说模型收敛的问题对吧
这个有可能你你的模型很复杂
你最后就是发现它不给你出任何结果
对吧那么这个时候
可能就是存在这个收敛的问题
然后还有自由度的问题
就是我们刚才其实已经碰到
这个自由度的问题
对吧
当我们试图把这个沉积模型和呃
从这辆发动飞机进行完全对应的时候
那么他的自由度的计算对吧
其实就是一个
就会有一些技术细节的问题
还有我们讲了这个随机统
计的这个
这个固定效应和随机效
随机效应对吧
那么还有包括像是固定效应主效应
这个简单效应对吧
后面这两个都是包含
武装老师在制服上的
这个帖子大家可以去看看
那么这里也都是非常值得去去关注的
然后大家如果做发展心理学
有一些这种
比方说交叉之后模型对吧
等等等等
还有这种呃
类似的这种前变量
可前前变量不是这个模呃
不是这样的呃
但是这个交叉之后他也是一个
就是我们碰到了这个呃
特定的模型呃
就是成绩模型的一个特例
所以今天我们只是给大家开了个头啊
希望大家能够感受到这个呃
这个大的统计框架的一个魅力
但是我们还有一个问题啊
就是大家可以想一想
我们今天其实是在刻意的
回避了一些数据
对吧就像我们上节课的时候
我们刻意回避了这个重复测量
放大分析的
这个就是引出了这节课内容
那么我们今天这个思思考比例
是要引出下一节课内容
就是当我们这个数据它
他不服从增长分布对吧
你都没办法去假设他是服从
服从增长分布的时候
怎么怎么办
比方说我们碰到这个正确率的数据
对吧在这个实验当中
你的正确率
你在如果你考虑每个试次的话
假如我们考虑每个试次的话
它其实就是0和一对吧
我要么就是错了0
要么就对了一对吧
大家可以想想
我们以前是用什么样的方法
来去对这个证据进行检验
那么他肯
定是很确定的
不太服不服从证的分布
对吧那么这种情况之下
我们比方说有很多的事实
我们最后算出了
他的这个平均的正确率
之后
我们把它做体检验或者帮助分析
也可以接受
对吧那么有没有更好的办法
或者有没有更加适合的办法
这个可能就是我们下节课要讲的内容
呃就是呃
回归模型
3今天我们就讲到这里啊
希望给大家开启了一个新的
一个知识的一个窗口
谢谢大家


# 以下是代码部分



## 准备工作
```{r }
# Packages
if (!requireNamespace('pacman', quietly = TRUE)) {
    install.packages('pacman')
}

pacman::p_load(
  # 本节课需要用到的 packages
  here, tidyverse, 
  # ANOVA & HLM
  bruceR, lmerTest, lme4, broom, afex, interactions)

options(scipen=99999,digits = 5)
```



---



#  一般线性模型回顾



---
# 0.1 线性模型与方差分析等价性



|       | R自带函数 | 线性模型 | 解释 |
|-------|-------|-------|-------|
| 单样本*t* | t.test(y, mu = 0) | lm(y ~ 1)| 仅有截距的回归模型 |
| 独立样本*t* | t.test( $y_1$, $y_2$) | lm(y ~ 1 + $G_2$)| 自变量为二分变量的回归模型 |
| 配对样本*t* | t.test( $y_1$, $y_2$, paired=T)  | lm( $y_1$ - $y_2$ ~ 1)| 仅有截距的回归模型)|
| 单因素ANOVA | aov(y ~ G) | lm(y ~ 1 + $G_1$ + $G_2$ + ...)| 一个离散自变量的回归模型 |
| 多因素ANOVA | aov(y ~ G * S) | lm(y ~ $G_1$ + $G_2$ + ... + $S_1$ + $S_2$ + ...)| 多个离散自变量的回归模型 |





---
# 0.2 虚拟编码

```{r xaringan-panelset, echo=FALSE}
xaringanExtra::use_panelset()
```


[预处理]
```{r preprocessing}
df.penguin <- bruceR::import(here::here('data', 'penguin', 'penguin_rawdata.csv')) %>%
  dplyr::mutate(subjID = row_number()) %>%
  dplyr::select(subjID,Temperature_t1, Temperature_t2, socialdiversity, 
                Site, DEQ, romantic, ALEX1:ALEX16) %>%
  dplyr::filter(!is.na(Temperature_t1) & !is.na(Temperature_t2) & !is.na(DEQ)) %>%
  dplyr::mutate(romantic = factor(romantic, levels = c(1,2), 
                                  labels = c("恋爱", "单身")),  # 转化为因子
                Temperature = rowMeans(select(., starts_with("Temperature"))))

# 设定相应的标签
breaks <- c(0, 35, 50, 66.5)
labels <- c('热带', '温带', '寒温带')
# 创建新的变量
df.penguin$climate <- cut(df.penguin$DEQ, 
                          breaks = breaks, 
                          labels = labels)
```


[虚拟编码]

```{r}
# 比较不同气候条件下个体的体温是否存在差异：
## 虚拟编码
contrasts(df.penguin$climate) <- stats::contr.treatment(unique(df.penguin$climate))
### contr.treatment本质上创建了一个矩阵
### 由于3个分组，所以矩阵为2列


## 建立回归模型
lm_temp <- stats::lm(Temperature ~ climate,data = df.penguin)

```

[结果]



```{r}
## 输出回归系数
lm_temp %>% 
  tidy() %>% 
  select(1:3) %>% 
  mutate(across(where(is.numeric),
                ~round(., 3)))
```




```{r}
## 可以看到回归的结果以热带为基准，系数则为均值之差
df.penguin %>% 
  group_by(climate) %>% 
  summarise(mean = mean(Temperature)) %>% 
  as.data.frame() 
```




----------
虚拟编码方式很多，可参考[这里](https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#ORTHOGONAL)



---

重复测量方差分析与回归模型 




---
# 1 重复测量方差分析
## 1.1 数据与问题介绍


以match_raw.csv为例，一个2x2的被试内实验设计（Identity: Self vs. Other) x Valence: Moral vs. Immoral)），我们希望知道这两种条件之下被试的反应时是否存在显著差异


[预处理]
```{r}
mt_raw <- bruceR::import(here::here('data','match','match_raw.csv'))

mt_raw <- mt_raw %>% 
  tidyr::extract(Shape, 
                 into = c("Valence", "Identity"),
                 regex = "(moral|immoral)(Self|Other)",
                 remove = FALSE)
```

[数据展示]
```{r echo=FALSE}
head(mt_raw[3:12],5) %>% DT::datatable()
```



---
## 1.2 数据结构

```{r echo=FALSE, out.width='70%'}
knitr::include_graphics('picture/chp9/data.png')
```



-   将总变异分解为组间与组内

-   组内变异是主要关注对象，组间变异则要被控制






---
## 1.3 重复测量方差分析的实现


[ANOVA-bruceR]
```{r warning=FALSE}

mt_mean <- mt_raw %>%
  dplyr::filter(!is.na(RT) & Match == "match" & ACC == 1) %>%
  dplyr::group_by(Sub,Identity,Valence) %>%
  dplyr::summarise(RT = mean(RT)) %>%
  dplyr::ungroup()

##  本例为长数据
##  RUN IN CONSOLE!
##  球形检验输出：
bruceR::MANOVA(data = mt_mean,
       subID = 'Sub', # 被试编号
       dv= 'RT', # dependent variable
       within = c('Identity', 'Valence')) %>% capture.output() %>% .[c(33:37)]


```


[ANOVA-bruceR(输出)]
```{r warning=FALSE}
bruceR::MANOVA(data = mt_mean,
               subID = 'Sub',
               dv = 'RT',
               within = c('Identity', 'Valence')) %>%
  capture.output() %>% .[c(15:31)]
```


[ANOVA-afex]
```{r }
## bruceR::MANOVA 是对afex的封装
m_aov <- afex::aov_ez(
  data = mt_mean,
  id = 'Sub',
  dv = 'RT',
  within = c('Identity', 'Valence'))

m_aov
```





---
# 1.4 重复测量方差分析的不足


重复测量方差分析有没有局限性？


--


-   个体间差异同样无法估计；



-   处理缺失值只能将整行观测删除，会导致标准误增加、功效降低；



-   对因变量(连续)和自变量(分类)的类型有要求；




-   对每一个试次中数据利用率低，造成试次的浪费





---
# 1.4 重复测量方差分析的不足


重复测量方差分析有没有局限性？


```{r echo=FALSE, out.width='45%'}
knitr::include_graphics('picture/chp9/Neuron_LMM.png')
```



*因此，现在越来越多的期刊推荐使用多层线性回归(Hierarchical Linear Model) ，如[Neuron](https://www.sciencedirect.com/science/article/pii/S089662732100845X)。*




---
# 2 多层线性模型(HLM)简介




分层线性模型/多层线性模型(HLM): 用于处理"多层嵌套数据"，在一个以上层次上变化参数的线性模型。但多层线性模型的名字非常多，不同学科称呼不同，有许多“近义词”：]

    -   层级/分层模型（Hierarchical Model，HM）  
    
    -   多水平模型（Multilevel Model，MLM）
    
    -   线性混合模型（Linear Mixed Model）
    
    -   混合效应模型（Mixed Effects Model）
    
    -   随机效应模型（Random Effects Model）
    
    -   随机系数模型（Random Coefficients Model）.....




但在注意与多元回归(multiple regression)进行区分，即逐步引入自变量到回归模型中，以检验每个自变量对因变量的影响是否独立于其他自变量


---

# 2.1 多层线性模型(HLM)的关键概念：固定效应与随机效应

---

在回归模型中一般会在截距和斜率上分别讨论**固定效应**和**随机效应**。

例如，关于研究教师的工龄(Experience)与薪水(Salary)之间是否存在关系。在某校随机抽取了5个学院的教师信息，具体数据如下：]


```{r echo=FALSE}
## 创建虚拟数据
set.seed(999)
departments <- c('sociology', 'biology', 'english', 'informatics', 'statistics')
base.salaries <- c(40000, 50000, 60000, 70000, 80000)
annual.raises <- c(2000, 500, 500, 1700, 500)
faculty.per.dept <- 20
total.faculty <- faculty.per.dept * length(departments)

# Generate dataframe of faculty and (random) years of experience
ids <- 1:total.faculty
department <- rep(departments, faculty.per.dept)
experience <- floor(runif(total.faculty, 0, 10))
bases <- rep(base.salaries, faculty.per.dept) * runif(total.faculty, .9, 1.1) # noise
raises <- rep(annual.raises, faculty.per.dept) * runif(total.faculty, .9, 1.1) # noise
df <- data.frame(ids, department, bases, experience, raises)
# Generate salaries (base + experience * raise)
df <- df %>% mutate(
    salary = bases + experience * raises
)
```


```{r echo=FALSE}
df %>% mutate(across(where(is.numeric),~round(.,3))) %>% head(6) %>% DT::datatable()
```



```{r echo=FALSE}

# Model without respect to grouping
m0 <- stats::lm(salary ~ experience, data=df)
df$simple.model <- predict(m0)

# Model with varying intercept
m1 <- lme4::lmer(salary ~ experience + (1|department), data = df)
df$random.intercpet.preds <- predict(m1)

# 可能会碰到错误
# remove.packages("Matrix")
# remove.packages("lme4")
# install.packages("lme4", type = "source")

# Model with varying slope
m2 <- lme4::lmer(salary ~ experience + (0 + experience|department), data=df)
df$random.slope.preds <- predict(m2)

# Model with varying slope and intercept
m3 <- lme4::lmer(salary ~ experience + (1 + experience|department), data=df)
df$random.slope.int.preds <- predict(m3)
```




----------
数据来源见(https://github.com/mkfreeman/hierarchical-models/blob/master/generate-data.R)





---

## 2.2 固定效应与随机效应

---

问题：是否可用工龄预测某个学校员工的工资？]


[数据结构]
```{r echo=FALSE,out.width='80%'}
include_graphics('picture/chp9/nest.png')
```


[OLS]

```{r echo=FALSE}
###  plot
df %>% 
  ggplot(aes(x = experience,y = salary)) + 
  geom_point(aes(x = experience,
                 y = salary,color = department),
             size = 5,alpha = 0.5) + 
  geom_smooth(method = 'lm',color = 'black',se=F,size = 0.5)  + 
  labs(x = 'Experience',y = 'Salary',legends = 'Department') + 
  scale_colour_discrete('Department') +
  bruceR::theme_bruce()
```





---


似乎可以。但有两个问题：

-   不同学院的底薪有可能存在差异（存在/不存在）

-   不同学院间间，工资与工龄的关系存在差异（存在/不存在）

这意味有可能会出现四种情况
]

--



对应在图中，则会在截距与斜率之间出现差异：

1.    不同学院的底薪相同，工资涨幅也相同；（固定截距，固定斜率）

2.    不同学院间底薪不同，但工资涨幅相同；（随机截距，固定斜率）

3.    不同学院间底薪相同，但工资涨幅不同；（固定截距，随机斜率）

4.    不同学院间底薪和工资涨幅都不相同。（随机截距，随机斜率）

画图看看.



---


[fixI-fixS]
```{r echo=FALSE}
###  plot
df %>% 
  ggplot(aes(x = experience,y = salary)) + 
  geom_point(aes(x = experience,
                 y = salary,color = department),
             size = 5,alpha = 0.5) + 
  geom_smooth(method = 'lm',color = 'black',se=F)  + 
  labs(x = 'Experience',y = 'Salary',legends = 'Department') + 
  scale_colour_discrete('Department') +
  ggtitle("Fixed Slope and Intercept") +
  bruceR::theme_bruce()
```


[ranI-fixS]

```{r echo=FALSE}
df %>% 
  ggplot() +
  geom_point(data = df,aes(x = experience,y = salary,
                           color = department),
             size = 5,alpha = 0.4) + 
  geom_line(aes(x=experience, y=random.intercpet.preds, 
             group = department, colour = department)) + 
  labs(x="Experience", y="Salary") +
  ggtitle("Varying Intercept") + 
  scale_colour_discrete('Department') +
  bruceR::theme_bruce()
```


[fixI-ranS]

```{r echo=FALSE}
df %>% 
  ggplot() +
    geom_point(data = df,aes(x = experience,y = salary,
                             color = department),
               size = 5,alpha = 0.4) + 
    geom_line(aes(x=experience, y=random.slope.preds, 
                  group = department, colour = department)) + 
    labs(x="Experience", y="Salary") +
    ggtitle("Varying Slope") + 
    scale_colour_discrete('Department') + 
  bruceR::theme_bruce()
```

[ranI-ranS]

```{r echo=FALSE}
df %>% 
    ggplot(aes(x = experience,y = salary,color = department)) + 
    geom_point(size = 5,alpha = 0.4) + 
    geom_smooth(method = 'lm',se = F,size = 0.5) +
  labs(x="Experience", y="Salary") +
    ggtitle("Varying Slope and Intercept") +
    bruceR::theme_bruce() 
```





---
layout: false
## 2.3 两种数据结构的比较

无论在我们的数据中，还是刚才的数据中，其实都出现了层级或嵌套关系；只是对于match数据，每个变量都嵌套在一个被试中，而每个被试都可视为一条回归线。



[两种效应]


-   固定效应代表了实验中稳定的、总体水平上的效应，即它们在不同个体、群体或条件之间的影响是一致的，如match数据中Identity和Valence的效应

-   随机效应则表示了数据中的随机变异或个体间的差异的程度，以及这种变异程度如何随着特定分组因素的变化而变化。




[match_data]
```{r echo=FALSE,out.width='70%'}
include_graphics('picture/chp9/data.png')
```

[shcool]
```{r echo=FALSE,out.width='80%'}
include_graphics('picture/chp9/nest.png')
```




---

对于match数据，类比与学校员工薪水数据，我们也可以设想：

-   不同被试总体上会不会存在反应时上的差异：有些个体普遍反应速度更快，而有些反应速度普遍更慢（随机截距）

-   在自我条件下，两种Valence的差异是否完全相同？还是会有个体差异？（随机斜率）


画图尝试一下，计算被试平均反应时后进行排序，选取首尾的几名被试：
]

```{r echo=FALSE,fig.height=5.8}
mt_sample_df <- mt_raw %>% 
  dplyr::filter(Match == 'match' & ACC == 1) %>% 
  dplyr::filter(Sub %in% c(7311,7313, 7307, 7324)) %>%
  dplyr::mutate(Sub = factor(Sub),
                Identity = factor(Identity, levels = c("Self", "Other")),
                Valence = factor(Valence, levels = c("moral", "immoral")))

mt_sample_df %>%
    dplyr::filter(Identity == 'Self') %>%
    ggplot(aes(x = Valence, color = Valence, y = RT))  + 
    geom_point(position = position_jitter(0.2),alpha = 1) +
    stat_summary(fun.y = "mean", geom = "point", 
                 shape = 18, size = 4, color = "darkred") +
    stat_summary(fun.y = "mean", geom = "line", 
                 aes(group = 1), color = "darkred") +
    facet_wrap(~Sub, nrow = 1) +
    scale_color_brewer(palette = 'Accent')+
    theme_bw(base_size = 13)
```





---
# 3 多层线性模型的应用
## 3.1 基本形式


我们使用lme4包对多层线性模型建模，具体语句形式如下：



```{r eval=FALSE, highlight=TRUE}
fit <- lme4::lmer(
    data =   , 
    formula = DV ~ Fixed_Factor + (Random_intercept + Random_Slope | Random_Factor)) #<<
```

--

注：

-   **但在建立模型之前，需要考虑好在我们的数据中，随机效应和固定效应分别是什么**。一般都会添加随机截距，而随机斜率的加入应当考虑是否有充足理由；

-   另外，由于随机效应是从某些总体中抽样的离散单位，因而本质上是分类变量



---
## 3.2 建立模型


[ranI]
```{r}
## 随机截距 固定斜率
model <- lme4::lmer(data = mt_raw,
                    RT ~ Identity * Valence + (1|Sub))

```



-   Identity\*Valence:  \*表示两变量间所有可能的形式，等同与Identity + Valence + Identity:Valence

-   (1|Sub): 1表示随机截距（0则表示固定截距）； 管道(|)右侧Sub为随机因子
]


[ranI ranS]

```{r }
## 随机截距 随机斜率
model_full <- lme4::lmer(data = mt_raw,
                         RT ~ Identity * Valence + (1 + Identity * Valence|Sub)) 
```



-   Identity \* Valence:  \*表示两变量间所有可能的形式，等同与Identity + Valence + Identity:Valence

-   (1|Sub): 1表示随机截距（0则表示固定截距）； 管道(|)右侧Sub为随机因子
]

[模型比较]
```{r}
## 模型比较
stats::anova(model, model_full) %>% capture.output()
```





------
注：模型比较的指标、计算方法及其优劣请参考[《认知建模中模型比较的方法》](https://chinaxiv.org/abs/202308.00658)



---
## 3.3 似然比检验(Likelihood-ratio tests)


[问题]

在建立模型后，我们希望知道固定效应大小是否显著，但由于多层线性模型中对于自由度的估计有多种方法，比较复杂，所以lme4::lmer()中没有提供显著性。
]

[anova]
```{r}
# 建立没有固定效应的“空模型”
model_null <- lme4::lmer(data = mt_raw,
                   RT ~ (1 + Identity*Valence|Sub))

## 根据似然比进行模型比较
stats::anova(model_full, model_null)

```



[mixed]

在模型非常复杂时（多层嵌套），如果仅仅只想对固定效应进行检验，可以使用afex::mixed()，设置method 参数为 LRT(Likelihood-ratio tests)

```{r highlight=TRUE}
afex::mixed(data = mt_raw,
            RT ~ Identity * Valence + (1 + Identity*Valence|Sub),
            method = 'LRT') #<<
```


[lmerTest]

lmerTest是一个与lme4包兼容的包，主要用于对混合效应模型进行假设检验；其中也包含了lmerTest::lmer()函数，与lme4::lmer()不同的是，其结果报告了显著性（使用Satterthwaite分母自由）

```{r}
lmer_model <- lmerTest::lmer(data = mt_raw,
                             RT ~ Identity * Valence + (1 + Identity * Valence|Sub))
# summary(lmer_model)

# 如果使用lmerTest包进行建模，可以使用bruceR::HLM_summary()进行输出
##  RUN IN CONSOLE
# HLM_summary(lmer_model)
```






---
## 3.4 模型解读


[随机效应]
注意：
-   相关矩阵会体现自变量效应在个体上的差异，尤其是第一列(截距与斜率的相关)，而具体的解释也应考虑对应固定效应系数本身的正负；  

-   有可能会提供天花板与地板效应的相关信息，如任务过于简单，数据变化较小，有可能出现截距与斜率为负相关。

```{r echo=FALSE}
summary(model_full) %>% capture.output() %>% .[c(11:18)]


```


[固定效应]

```{r echo=FALSE}
## 使用lme4::lmer()并没有返回显著性
## 其中也报告了交互效应
summary(model_full) %>% capture.output() %>% .[c(20:25)]

```


[交互效应的可视化]
```{r fig.height=5,fig.width=6}
## 一种快捷的方法
interactions::cat_plot(model = model_full,
                       pred = Identity,
                       modx = Valence)
```









---
## 3.5 模型等价性


如果我们观察一下使用lme4::lmer()的结果与重复测量结果，可以发现存在差异：




[anova]


```{r}
m_aov
```

[lme4]
```{r}
## 使用lme4建立的模型
model_full %>% anova()
```

[lmerTest]


```{r}
## 使用lmerTest建立的模型
lmer_model %>% anova()
```





---

```{r }
# http://www.dwoll.de/rexrepos/posts/anovaMixed.html#two-way-repeated-measures-anova-rbf-pq-design

model_aov <- mt_mean %>%
  # dplyr::filter(!is.na(RT) & Match == "match" & ACC == 1) %>%
  lmerTest::lmer(
   data = .,
   RT ~ Identity * Valence + (1|Sub) + (1|Identity:Sub) + (1|Valence:Sub)
 )

model_aov %>% anova()
```





---
#  4 HLM的应用



HLM 非常复杂，本节课仅以重复测量为例，下面提供了一些其他的应用场景：




[嵌套数据]

```{r echo=FALSE}
include_graphics('picture/chp9/nestdesign.jpg')
```
[元分析1]

通过综合一组研究来评估效应量的大小。由于不同研究的结果之间往往涉及到不同质的群体或不同的实验条件。

```{r echo=FALSE, out.width="85%"}
include_graphics('picture/chp9/meta1.jpg')
```

[元分析2]
```{r echo=FALSE, out.width="60%"}
include_graphics('picture/chp9/meta2.jpg')
```





---
# 5 可能遇到的问题


-   模型不收敛：[混合线性模型的实现](https://zhuanlan.zhihu.com/p/63092231)

-   自由度问题：[多层线性模型（HLM）及其自由度问题](https://zhuanlan.zhihu.com/p/50048784)  

-   [统计学中的固定效应 vs. 随机效应](https://zhuanlan.zhihu.com/p/60528092)

-   [「固定效应、主效应、简单效应」概念辨析](https://zhuanlan.zhihu.com/p/513227882)



---


思考


<span style="font-size: 50px;">当因变量不服从正态分布(如ACC)时如何处理？





