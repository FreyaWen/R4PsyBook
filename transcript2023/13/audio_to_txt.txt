一个push 在那个提醒我就是大家已经完成了 可能只有一两个同学不小心搞错了 但基本上都没什么太大问题 可能这个关于GitHub的确实应该早一点把它交给大家 这样的话可能大家有更多的时间去练习 以及使用这个课件 我们今天讲一个 就可能在心理统计学里面应该讲 但是实际上我们本科心理统计学没有讲 不知道大家在其他课里面 提到的一个很重要的一个 一个统计学的概念叫效应量 现在有没有哪个统计学的课程 大家在YouTube的统计学课程设计到这个概念了 都没有啊 SPI的课有没有讲这个 我们今天不会花很多时间讲 但是我觉得今天的这个课程有点类似于 就是给大家打一些基础 就是关于效应量的一些基础 那么并不是说上完这门课之后 大家就会有一个分析或者说能够去 非常熟练的去计算各种各样的效应量 这个估计还是有点困难 因为大家后面会看到效应量的软件分析 其实它很依赖于 就是你的整个研究问题和你这个context 所以如何去解读效应它不是一个技术的问题 它是既需要你懂统计的方法 也需要你对你这个研究领域很熟悉 那么效应量属于什么效应量 提到效应量大家一定会想到Constit 但实际上真正对效应量的一个定义 就是说是研究者感兴趣的任何的效应量 只要你对它感兴趣 你觉得它有意义 你就可以认为它是你的一个效应量 所以效应量它本质上就是效应的量 就是effects 那么这个effect的话 这个effect本身对吧 你只要是你对你的研究有兴趣的 对你的理论有意义的 都是effect对吧 那么我们心理学为什么会通常是closed in的 就是因为我们很多时候是比较不同组之间的一个差异 而不同组之间的一个差异进行比较的时候 我们可能希望摆脱它的原始单位的一个影响 那么就变成了一个 某种程度上是一个没有单位的一个标准化的一个统计量 那么在其他的领域 实际上很多时候大家不一定会真的对这种标准化的效应量感兴趣 那比方说大家 我们最常见的有的时候我们会看到 说这个家庭的这个 家庭的背景对吧 家庭的背景如何会影响子女的教育成就 那么这个可能是大家很关心的一个问题 比方说近些年有什么阶层固化啊等等对吧 那么对于教育学的研究者来说 他会关心你这个标准化的效应量是多少吗 你告诉他constant 等于0.2 或者0.4 其实很难去解读它到底代表什么意义对吧 那么在这种情况之下大家一般会用什么作为效应量 就是你大概比 比方说你每变化你的一个家庭的收入对吧 比方说每个月多1000元 那么你的子女的教育会多多少年份对吧 几个月 那比方说你的 我们到高中的话就是九年义务教育加三年的高中教育就是12年对吧 那你就是12年的教育 然后你再加上四年的这个大学教育的话就是16年对吧 然后你再加研究生的三年的话就19年 也就是说他最后就可以把子女的教育用这个 受教育的年份来进行一个量化 然后把家庭的这个背景比方说用这个 收入来进行量化那么最后就考察就是你的家庭收入 对你子女的教育的这个接受教育年份的一个影响 最后就是用年份来进行量化 或者说你用你这个所取得的一个学位的量化对吧 那么在这种研究当中的话基本上都是 直接以实际的这个生活中的这个效应 作为一个效应量而不是说 我以什么quantity为效应量或者相关系数对吧 因为这个地方你用受教育的年份的时候是 第一更有实际意义的第二大家也更容易接受对吧 所以首先效应量这个大家一定要明确 它不是一个任何一个统计的指标 它就是一个大家感兴趣的量 那么在心理学的研究当中的话我们常常会碰到这个 尤其是前面两类对吧就是这个D family或者是R family对吧 D family就是difference或者standard difference 那么我们所熟悉的cosd和hg 还有什么各种关于cosd的一个校正的公式对吧 它基本上都是属于这一大类 那么另外一个就是基于相关的这个 一系列的一个统计指标对吧 包括相关系数然后包括那个R2包括E2 然后包括ω2还有那个F对吧 那么这些它要么是说 你两个变量之间有多大相关系数对吧 另外一个就是说你的这个某一个效应 它所解释的变异在总体的变异当中占多大的比例对吧 那就是我们最熟悉的两类的这个统计指标 那么在医学领域的话它可能有的时候 会很重视这个叫做 Ost ratio对吧或者叫risk ratio 因为在临床上面它可能就是说我治疗了之后 这个病人会不会能不能生存下去 生存多久对吧 你一种药它的这个最后带来的这个生存 或者叫做risk对吧 它会不会比另外一个risk更大 所以不同的研究领域它可能用的效应量也不一样 那么相对来说相关系数可能是一个最通用的 它可能会比这个D方面会更加通用 然后你可以用Ost ratio转到这个相关系数 然后D的话也可以转到这个相关系数 很多都可以转到这个相关系数这个效应量 然后如果大家看这个像比方说 Psychological Bulletin对吧 Psychological Bulletin就是我们心理学领域 这个最发原分析最多的一个期刊 而且影响力非常高 那么它上面的很多的这个原分析的话 基本上都是以相关系数做一个effect size 那么这是关于这个effect size 那么在这个effect size这个 实际上它受到重视的话 应该是也就是近10年来的这个事情 那么在2011年的时候 JP General就是那个 General of Experimental Psychology General那个杂志 它专门回顾了这个 发表在这个JPG上面的文章 那么他们到底报告了什么效应量 这里没有引用 当时他们发现了一个非常有趣的效应就是 报告最多的其实是Partial Yield Squared 就是我们说的偏Yield方 那么很重要的一个原因就是什么 就是因为SPS输出这个东西 所以说其实SPS输出之后大家就报告多 SPS不输出大家就不报告 包括最简单的Quantity 那么我如果大家对这个感兴趣 我强烈推荐大家去看这个Daniel Narkins这个 这个文章就是Frontiers 他这个可能是Frontiers in Psychology 引用的最高的文献之一2013年的 那么在他的这个文章里面 他提到了几种这个Quantity的各种各样的指标 所以我们可以看到虽然说 Quantity对吧它是一个我们非常常见的一个效应量 但是呢它实际上有很多很多种 这个不同的计算方法或者应对很多不同的条件 那比方说这个Hedges-G对吧 联合方差那么它是适用于独立样本 它是校正这个小样本的一个偏差对吧 然后Hedges还有GAV对吧相关样本的 就是我们说的这个配对样本的对吧 那么他用于语言分析的时候一般就是 相当于一方面他考虑了两个组之间的一个方差的一个 就属于是相关的对吧 另外呢他也进行了一个校正 还有等等其他的 所以我们可以看到这里的话就会有很多这种不同的 计算的方法 那么每一种不同方法的话 可能又会有他自己的一些细微的区别 所以当我们说效应量的时候 也就是说Quantity的时候 它其实并不指的是某一个特定的一个单一的计算方法 它可能是指的是一系列的计算方法 我们后面会看到的 那么关于Eta2也是如此 Eta2一般来说就是 我们最常见的那个Eta2对吧 它实际上是单个研究内部之间不同变量的效应量大小 那个Parsity2它可以是用于统计简易分析 或者是比较具有相同实验设计的一个 相同实验设计的这个研究之间的效应量 那么大家可以看到 它是用了比较相同实验设计对吧 所以Parsity2它其实不太适合做原分析 为什么呢 因为它其实只考虑了 它在考虑你这个就是解释啊 就你这个某一个质量它所解释的变异占比的时候 它那个分母的部分它其实并不是全部的变异 而是一部分的变异 那么所以后来2003年的时候 有人提出了一个叫做Generalized Eta2 那么就是用来进行跨研究的一个比较 那么一般来说会推荐使用这个Generalized Eta2 这也是那个Daniel Nuckes那本书的一个内容 那么现在呢关于效应量和自行区间的计算 一般来说是推荐 就推荐大家去在研究中既报告效应量 然后也报告这个效应量的自行区间 但实际上存在一个问题就是 对于SPSS的话 我不知道现在最近的最新版本有没有改进 但是至少几年前的话它仍然只有Pan-Eta2 它包括Quantity什么都没有 那么Jasper的话这个软件它相对来说的话 就是整合了最新的一些要求 包括Quantity的这个效应量和它的自行区间 然后还有Parsity2 Generalized Eta2基本上都有 然后Nuckes2013年的时候 他的那个文章附带了一个Excel的计算程序 这个实际上我估计是使他的那个文章的引用量 大大增加的一个很重要的一个方面 就是因为他提供这个Excel的一个工具非常好用 它上面有一个心理学家非常习惯的一个那种决策图 就是首先你的实验设计是什么 然后是不是表格配对 然后是,然后就下一个 然后不是,然后另外一个 就一步一步走下来 然后到最后之后他就告诉你去哪一个 他那个Excel表格里面有几个表单 他告诉你建表单几 然后你发明表单之后呢 他就会有几个地方是你可以填空格填你的数据的 然后你的组一的这个means是多少 SD是多少 组二的means是多少 SD是多少 然后这个你的每组的这个样本量是多少 然后他就会帮你计算出一个效应量和自行区间出来 所以他这个Excel表格呢应该是帮助了很多人 去计算这个效应量和自行区间 尤其是如果被要求一定要提供效应量和自行区间的话 那么我们我自己和几个研究生应该是上海师大的一个 特别优秀的一个研究生徐二培 我们还有那个中山大学 当时我还没有在南师大 中山大学的一个研究生叫王俊 我们一起写了一篇文章 后来发表在心理科学技术上面 就专门介绍了几种常用的 就是这个ANOVA和T-test的这个 Const D效应量和自行区间的一个 计算的一个中文的文章 里面有一些R的代码大家可以使用 但是我感觉就是这个领域发展真的很快啊 现在大家基本上用R的话就可以搞定全部的东西了 你可能已经不需要再去跑到各个地方去 去找这个工具了 那么还有就是稍微做一个提示就是说 在这个Gpower这个软件里面大家可能会 也会发现它可以用来计算这个效应量对吧 但是呢它和SPS输出的这个 Patches squared是不一样的 可能需要转换 那么丹尼尔纳肯斯在他的那个书里面 也提供了转换的公式 所以整体而言的话就是丹尼尔纳肯斯 那个书那本文那个文章的话其实是相当有用的 那么我们这个效应量的估计啊 它其实就回到了我们在统计书上 贴到的一个非常重要的一个概念是点估计 那么点估计的话一般有点估计的话就会区间估计对吧 所以说有效应量的点估计就会有95%的自行区间 那么这个参数估计啊或者点估计 在2012年的时候这个康明 他在一本书就叫The New Statistics 这本书里面他就 Understanding New Statistics 发现讲到就是我们应该去不仅仅使用IHSP就是我们说的P值 我们还要使用这个effect size 然后还要使用这个confidence interval和这个meta-analysis 那么这三个方法或者三个这个统计的指标都有一个共同特点 是什么呢 它就是叫做estimation based 就它是专门基于估计的 那么这个基于估计它跟我们传统的基于P值二分法 它就有一个好处 就是说你不仅仅可以看到你的效应量是不是显著对吧 而且你要看到你这个效应量到底有多大 那么这个实际上是很重要的 把心理学研究和现实的因素 就和现实的这个我们说现实的世界进行关联的一个很重要的一个点 比方说你发现某一个效应它很显著 但是它的效应量可能非常微弱 那么它的这个社会到底有没有意义 可能没有任何的意义对吧 然后如果说你有的时候你可能是一个非常小的一个效应对吧 但是它确实它没有任何的坏处 而且它的成本很低 那么这个时候的话 只要你对它实施的话 它可能会改变一部分人的命运 那么你这个时候是不是可以考虑 就把你的这个方法介绍到比方说现实的这个世界对吧 那么我可以举一个例子 就是大家可能听说过一个概念叫growth mindset对吧 叫做成长性思维 那么成长性思维的话 这个在教育学里面非常受到追捕 它是斯坦福一个心理学界的老师 叫做Karl所提倡的一个 那么基于它这个growth mindset 也有很多行为的培训 但是也有很多的研究结果 对它的培训的效果表示质疑 所以他们后来在应该是在2020年的时候 在NASA上发了一个很大规模的一个 就是类似于RCT的一个研究 那么他们在美国的各个地方进行了一个 类似于随机双盲的一个测试 然后去检验进行这个growth mindset 这么一个训练 成长性思维训练 到底会不会对学生起到一个剂作用 那么最后他们发现了有一个非常微弱的一个效应 大概是constance可能是0.1还是0.2 大家可以看到constance 0.1 0.2的话 其实要比我们这里所说的这个100社会频率 平均的像小 当时这个结果出来之后就引起了很大的一个争议 一方面就是Carroll他们本来支持growth mindset 这帮人就会认为你看我们这个是有效的 对吧 我们这个constance不是0对吧 它是0.1 但是另一批人他们就说你这个其实是跟控制条件相比的 就是控制条件它其实是没有做什么太多的干预对吧 那你的growth mindset你应该除了评价它的这个微弱的效应量以外 你还要考虑它的实际的效果 就是你投入到这个growth mindset这种训练 你要花费多少精力对吧 你的这个精力是不是值得的 那么这就肯定就是把我们心理学的研究 心理学的概念和现实的世界进行的观念 对吧 当你要去考虑你要不要实施某一个研究 或者说你觉得你自己的某一个心理学的某一个理论 是不是真的能够帮助人们 而变得更好的时候 就一定要去考虑它的这个现实的效果对吧 那么在疫情期间的话 那个像什么助推的这样的一些心理学的概念也是很重要的 就是它到底有没有效应对吧 那么在像样的解读当中的话 我们传统上 我专门把这个highlight一下 就是我们一定要注意就是不要使用所谓的 Cohen的small medium和large 就是这种effect size对吧 就是这个是实际上是雅虎Cohen在60年代提出来的 那么他当时提出来的时候 我们大概想了一下 就根本就想不出来 他叫什么low-farm 就是说我们是一个直觉上面一个很简单的化学 那么在心理学里面 就是或者在整个科研领域 就会出现一个很奇怪的一个现象 一旦你把某个东西定为一个 在某一个发表的过程当中 你说它可以之后呢 然后很多人就会 我们可以说是 就是mindless使用它 就是说完全无脑的去使用它 就只要觉得它只要是Cohen-SD对吧 小于这个零点几 那我们就认为它是小的对吧 我们不管它的这个contact是什么 然后只要它0.8 我们就认为它大了对吧 我也不管它的效应 它的样本量有多大等等等等 在我们的这个研究中 我希望大家还是需要去避免这个 简单的套用这个一个 关于效应量大小的一个划分 而是要看你的这个研究背景 怎么看你的研究背景 就像我刚刚说的 你要去考虑你的这个研究的实际 或者理论的意义 那么另外一个就是 这是这个叫做estimation-based statistics 里面非常重要的一个概念就是 我们一定要去理解这个点估计对吧 或者效应量的估计它到底是什么 它实际上是代表的是每一次采样当中 我们跟一样的估计出来的一个量 那么至于说这个效应量 以及它的CI是否包含整体的话 其实它会每个都在不断的变 那么这是早期的这个Comi 它在它自己的那个软件 能够做出这样的模拟 就是说比方说你可以设定 你的效应量是多大对吧 然后你的你用多少样本量 然后这样的话 它就可以帮你模拟出这个 比方说从这么大的一个效应量里面 去抽取多少个样本 然后去估计 然后再来去看这个CI 到底有没有包含这个增值的 所以的话我们可以看到 这个点估计效应量都是在不断的变动 那么大家如果感兴趣的话 可以看一下有一个更新的版本 叫R-Psychologist 这个网站上 它其实能够非常明显的看到 这个CI的一个变化 大家可以看到它就是在不断的去计算 帮你做这个模拟 大家可以看到这个CI在不断的变化对吧 那么有一些CI它其实是 不会包含这个虚线的增值的 它就会比较少红色 到目前为止都包含了对吧 你还可以让它更快一点 它这个地方就有一个红色了对吧 OK那因为我们这个课不是专门讲这个统计 所以我们就还是回到我们这个相关的 那既然这个效应量和自行虚线 那么它我们每一个研究 其实就相当于是里面的一个样子 我们比方说我们做30个 就相对是我们从某一个总体里面 我们抽取了30个 然后我们分析出30个 我们估计出来我们的效应量 然后我们估计出了一个CI 那么这样的话我们就可以 我们可以至少在我们想象中 我们可以看到 就是说我们可以 其实有可能有无数个平行的实验对吧 那么这无数个平行的实验 我们能不能把它累加到一起 那么这样的话能够更好的去估计 这个整体的一个效应量对吧 那这就是我们这个原分析 也就是当我们知道了 效应量和自行虚线只不过是一个样本 单次采样的一个数据之后的话 那么我们就可以把它想办法把它综合起来对吧 那么我们接下来要做的就是 如何去计算单个研究综合 或者单个样本当中它的一个效应量 自行虚线以及我们如何把它综合起来 因为我们是一个R语言的课 所以我们还是要进行实现它对吧 不是单纯讲那些概念 那么我们可以简单的看一下它的公式 这个公式其实对于Quantity来说非常简单 大家可以看我们Quantity S就是这个 下面来的单纯的说 它就是X1的均值 这里写的是少的那个8 就是X1的均值减去X2的均值除以它的X1 这个大家是不是很熟悉 它实际上就是一个标准化的 上面是均值下面是一个S1 它本质上就是跟我们的Z值是很像的 它就是把我们的一个差异性的一个标准化 然后的话它就能够得到就是进行跨研究进行一个比较对吧 因为你已经变成一个标准化的差异值了 所以甚至我们可以想象就是说 在最简单的一个T-test里面 我们一般是说我们的效应量为0对不对 而且就是没有效应没有差异对吧 那么X1-X2我们是不是可以把它简化成 进一步简化成一个叫做Xdifference对吧 那么就变成了Xdifference-0对吧 那么假设这个0是我们的均值对吧 所以我们加上一个均值的话 它就是变成了一个在一个样本上面对吧 它代表的是一次错样对吧 一次错样的一个mean difference 然后减去一个理论上的一个mean difference 就是0对吧 然后再除以它的一个Xd的话 那就是一个标准化的一个分数对吧 所以cosd它本质上它就是一个标准分数 它只不过是在不同的情况之下有不同的计算方法 那比方说我们这里算的是这种独立样本对吧 就是有两个独立样本 它做在两个独立样本的时候我们如何来算它对吧 这里实际上就是一个对这个SD的一个加权对不对 就是N1-1对吧 然后乘以SD1 然后这就是一个简单的一个加权对不对 那么Hedges-G的话就是在cosd的基础质上 然后乘以一个校正的一个项对吧 那么校正的这个项大家可以看到 当我们的N越大的时候它的这个影响就会越小 N越小的时候它校正会越多 那么还有就是对于这个配的样本 配的样本这个好像没有出来 我再打开一下看它会不会出来 因为我们这是用那个markdown的语法写的公式 所以还需要把它的一个公式叫做rand出来 还是没有出来 这个地方大家可以看到它实际上就是做了两个部分的 第一个就是在这里做了一个校正 这个地方写成公式 我手动的那一步 它前面就是它的分母就是这个mean difference 然后它的这个下面的 就是有一个分母 这个分母的就是square root对吧 square root下面有一个sde的方 sde的平方 然后加上sdr 再减去2乘以相关系数 乘以sde乘以sdr 这实际上就是对相关样本的这个 这个pool的sd就是联合的sd的一个校正对吧 然后再乘以一个校正的一个系数 就是square root 然后下 2乘以1加2 那么下面的这个应该更简单了 上面还是一样的 下面就是两个sd看到没有 两个sd sd1加sd2然后除以2 这是一个更加简单粗暴的一个方法 也就是说大概就是这样大家可以看到在配的样本的时候,我们有两个计算的方法 一个是我们只知道定义的SD的时候 我们可以用这个方法计算 另外我们有原始数据的时候,其实我们就可以算那个相关系数 有原始数据的时候,算相关系数的话,就可以用上面的那些因子 在丹利纳克斯那本书里面,他的推荐就是这两个都可以用 OK,那我们来计算一下Const D 首先我们来计算什么Const D呢 我们计算一下这个,就是我们之前用过了多次的这个数据 就是那个matching的这个数据 在matching这个数据里面,我们知道有不同的条件 有比方说第一个是match,就是分成两种,一个是match,一个是mismatch 第二个就是identity,一个是自我误差 第三个就是这个,它的这个valence是好还是坏 那么大家可以看到,我们要计算Const D的时候,其实我们那个 这个这个,它只能算两种条件的一个标准化的差异值 那么这就意味着我们在计算Const D的时候,一定要明确清楚 就是一定要清楚自己要对哪一个感兴趣 否则的话,你就,你只能说我就每个都计算对吧 那么我们在这里的话,我们感兴趣的就是match条件下 好我和好人的一个区别对吧,比方说我们 我们想知道自我的一个优势效应 在好的情况下,它的一个优势效应对吧 所以这个时候我们就需要 我们需要去计算这两种条件之间的一个差异值 那么这个时候我们就需要用到前面 我们在前上上周就chapter 11的时候 那个那节课里面的数据清理 我们要算到算出每一个倍是在每种条件下的一个 反应时的一个均值 而且比方说我们只有正确反应对吧 然后是反应RT大于200毫秒的 就是说把这些无效的排除掉对吧 然后我们通过前面的预处理对吧 把这个图形的两个条件代表两个条件分开 分开了之后把它进行一个名称进行一个变化 然后使用这个mini seconds对吧 然后呢再把它进行一个mutate 这是我们第11章就是讲那个画图的时候 我们当时用到的这个数据对吧 大家还记得的话如果我们 我们当时画图的时候是用一个一个base的 一个一个点的数据对吧 把它画成背景的那个点 那么这个数据也可以用来我们做这个 效应量的一个计算 那么如果我们感兴趣的效应量是max效应量 好人和好我之间的平均反应是差异的话 那么我们所计算所需要的一个效应量 那我们就要看这个对吧 基本上就是这个公式 那么这个公式mean difference 就是说要是两个条件之间的一个RT的一个差值对吧 然后呢我们也需要知道它们的一个SD1 SD2对吧还有它们的一个相关系数 所以我们要知道基本上就是五个变量对吧 一个是条件1的一个RT 就是主水平的一个RT 条件2的一个主水平的RT 第三个就是条件1的主水平的一个SD 然后第四个就是条件2的一个主水平的SD对吧 上面两个就是得到了 上面这个分母对吧 然后下面的话我们再得到这些 然后呢把它们求一个相关系数 相关系数的话你就可以用每个倍数的 在两个条件之间的反应时间做一个相关对吧 然后这样的话我们就能够用这个公式进行校正 那我们接下来要做的就是这个事情 所以我们比方说就直接把它filt出来对吧 然后把这个match的和good的然后选出来 然后group by然后这个得到了就是 自我和他人条件下的一个情况对吧 然后呢我们这个时候 为了求相关系数我们这里用了一个非常 直接和就是非常符合直觉的方法 但是这个代码就会比较长 我们先把这个数据 把base这个数据对吧选出来了之后 选出两种对吧 只有在match条件上good good self和match good other 然后把它变成一个宽的形式 那么这个时候我们因为选客三个只有一个是 只有identity 一个是一个self 其他的都是一模一样 然后呢我们就把它变成一个宽的数据 宽的数据的话我们用一个简单的一个correlation 就可以看到它 然后可以把它求出来 然后我们用我们可以自己手动的去算对吧 大家可以看到这个手动的算 就是看起来比较复杂 但实际上就是我们把一个一个的变量 带到这个公式里面去 然后算出来 ok 然后这样的话我们就得到了一个quantity 就是-0.568 这是手动算出来的 ok到现在为止大家有没有疑问 啊 为什么不-的 这个是quantity它正负应该不太影响 就标准化的这个标准化的 呃 叉值其实可以这么可以 因为你像就是就像我们这份数据 这份数据也是可以这么可以的 对不对 就关键是你要把谁放前面谁放后 我们这里是把自我放前面 自我的话其实 呃 反应更快 所以它的反应时间会更短 标准化之后的话它就是一个负值 ok还有别的问题吗 听起来非常简单 然后我们也可以用其他的一些方法来做 然后这个时候我们就发现 结果其实不一定是一模一样 比方说我这里采用的一个包 就是一个叫做effect size的一个包 那么它在这个 它这个包里面呢就可以直接把你的这个t-test 结果读出来 然后呢使用这个 它内置的一些公式去算 这个quantity它的反应时间 那么这时候我们可以看到 通过它的我们把前面的一模一样的这个数据 然后通过这个t-test做完之后把它做输入 输到这个effect size里面 然后就发现它给出来的动作是不一样的 而且区别还不小对吧 我们是-0.5对吧 它是-4.0 -0.48 所以实际上这个quantity它的这个公式非常之混乱了 以至于就是有人专门写博客 就说quantity到底代表的是什么 所以在我们这个情况之下的话呢 就是大家一定要看 比方说我们使用R包的时候 你最好要看它的那个参考文献 以及它的背后的公式 它到底使用的是什么样的一个代码 来去计算的这个quantity OK 那么我们在讲这个原分析之前 我们先做个练习 大家去比方说自己 前面我们这里有几个代码 大家把这个 那个 我们就说换一个条件吧 我们刚刚计算的是自我和他人的 在这个match条件下的 然后大家可以尝试一下 我们就是自我条件下的 然后好和坏 大家计算一下quantity 那么就是叫做match条件下 match条件下 然后它的自我 加自我条件 然后就是 好和坏的一个区别 大家可以进行一下教练 大家可以 我觉得可以 第一个就是 可以用三种包试一下 第一个就是手动的 第二个就是用effect size的工具包 第三个大家可以采用这个Brusa 因为我们之前都用 所以说这个是比较方便的 Brusa里面有一个ttest对不对 这个ttest它 它本身就是输出这个quantity的 大家可以对比一下 三个计算的是不是一样的 大家练习一下 这个代码刚刚已经上传了 应该核心代码在这 但这个地方其实有点看不出来 因为太长了这个代码 大家之前有用代码把公式转成代码 都没有过是吧 今天正好练习一下 我觉得这对于大家以后 降低对数学公式的恐惧感 是一个非常正常的一个练习 我自己当时在学MathLab的时候 就是大量的把代码 把数学公式转成代码之后 就不再对数学公式有恐惧感 我解答一下 謝謝各位 請不吝點贊訂閱轉發打賞支持明鏡與點點欄目 感謝觀眾朋友們收看本期節目 感謝觀眾朋友們收看本期節目 感謝觀眾朋友們收看本期節目 感謝觀眾朋友們收看本期節目 感謝觀眾朋友們收看本期節目 感謝觀眾朋友們收看本期節目 感謝觀眾朋友們收看本期節目 感謝觀眾朋友們收看本期節目求这个,然后这个地方我,比方说这个mean 然后选的第1个对吧,就是我们如何从这个数据框里面选 选我们自己想要的单个数值 当然这里可能可以用更复杂的办法,就是说 我让那个identity等于self的那个mean对吧 这样的话我们这个变量的名字就会特别差 所以我这里就是直接用1来表示了 要不然的话我们还要用一个逻辑的一个判断来选 然后同样的话我们因为前面这个self在这up在这对吧 所以的话就会出现这个情况 大家算出来吗,有同学算出来吗 还是说这还挺难 你算算是1.28是吧 ok我先把这边退出来,我看能不能演示一下 我先把这个逻辑选出来 然后我再把这个mean对吧 选这个mean对吧 然后选这个mean对吧 然后选这个mean对吧 然后选这个mean对吧 然后选这个mean对吧 然后选这个mean对吧 然后选这个mean对吧 然后选这个mean对吧 然后选这个mean对吧 然后选这个mean对吧 然后选这个mean对吧 然后选这个mean对吧 然后选这个mean对吧 然后选这个mean对吧 然后选这个mean对吧 然后选这个mean对吧 然后选这个mean对吧 然后选这个mean对吧 这个是什么 linux 我这边这个地方有很多包装店 我这边的包装店 我这边的包装店 我这边的包装店 我这边的包装店 我这边的包装店 我这边的包装店 我这边的包装店 我这边的包装店 我这边的包装店 我这边的包装店 我这边的包装店 我这边的包装店 我这边的包装店 这个店很多包都没有装啊 每次运行的时候它会 它会下载很多 它会下载很多 它会下载很多 它会下载很多 它会下载很多 我之前跟大家推荐过EasyState这个系列包啊 它是非常好用的 我觉得它基本上是跟这个Tidyverse是一样的 我觉得它基本上是跟这个Tidyverse是一样的 一个非常好的一个系列的包 一个非常好的一个系列的包 我这里刚刚读取了数据 大家如果能够看到的话 然后我来的Chunk2 Chunk2这个地方的那个 Chunk2这个地方的那个 清理数据啊实际上是我们第11张当中 清理数据啊实际上是我们第11张当中 直接用到过的对吧 我们这里就直接使用了 我们这里就直接使用了 然后我们看到它这个head是这样的对吧 每个条件都有一个均值 刚刚我们在那个 网页上面没有看到这个公式 它显示出来实际上应该是这样的 所以这个网页有的时候不太给力 所以这个网页有的时候不太给力 然后这个时候我们用一个非常粗暴的方法 然后这个时候我们用一个非常粗暴的方法 大家可以看到这里的 第一个为什么非常粗暴 第一个变量名非常长 然后每一个步骤都写出来了 这样的话有个好处就是 对于我们就是不太了解 这个就不太能够了解高度 这个就不太能够了解高度 封装这些代码的人来说的话 其实就很清晰 比方说我们第一个就是通过这个 对背试的进行一个选择对吧 对背试的进行一个选择对吧 这个filter match等于match 然后valence等于good 就是把所有这个good的选择对吧 对这个练习题的话这个选择条件会变对不对 选完了之后实际上就只有两组数据对吧 我们可以每一步 我之前建议过大家其实可以每一步 对这个管道的话 你就是选择一部分的代码去运行 然后看它运行的结果是什么 比方说我们这个 它运行出来的应该是这个对吧 选择了的 我们可以看到它这里的identity 就是有不同对吧self和other 这个match的话就全部只有match对吧 没有其他的 然后这个valence就只有good了 前面第一个是进行了一个选择对吧 然后group by之后 然后再通过这个 这个summarize求它的mean和difference 对吧,然后我们可以看到 这样求完了之后它其实只有两行了 对吧,这个identity就是 一个self一个other,然后就是mean 就是它的平均反应 这个是主水平的,就是对每个 base的平均反应时间再进行 一次平均,然后SD的话就是对 每个base的平均反应时间求了一个SD 对吧,这是实际上 是我们实验中非常常做的 然后我们把这个 刚才是求了一个均值 和标准差对吧,然后呢我还把 这两组数据呢把它 变成一个宽的数据,那么 我们可以再来看一下 这个地方我们可以先运行一下 它就变成了这个 常数据对吧,这个地方就是 我们刚刚看到的identity这里有不同对吧 然后valence和match都是一样的 然后我们就 把这一组把它变宽 对吧,就是把这个变成 两个columns,那么每一个 对应的就是它的RT的 这个均值对吧,然后我们 实际上就是用这个pivotwider对吧 然后很方便就 把它变成了这个宽的数据,然后我们 完整运行一下之后 我们看到它就是 更新一下 它这个地方就变成了 这样对吧,就是subject id,然后match,valence,然后就是 self,other对吧,然后我们就 算它们之间的一个相关,因为这个对我们求 手动算它这个 constit的话是必须的 我们可以看到它这个相关系数非常低对吧,0.2 实际上是一个 非常低的一个相关,那么这个也 很正常对吧,因为它不同条件下面 反应的模式不一样,也是可以 理解的 然后我们就是 直接手动的算这个对吧,我们可以看 这个括号里面的,首先是这里有一个 有一个 除号对吧,除号前面的 就是我们分母,然后除号的 这个 就是后面就是那个分子 square root就是 方差对吧,这些符号 的话大家用多了之后就比较熟悉了 然后我们用括号把它圈 起来的话就是让它按照 我们想要的这个 运算对吧,这个运算的 顺序,也就是说这个地方 是加减对吧,我们必须把它框起来 要不然的话它就是后面运算了 然后square root里面也是一个 大家可以看到,square root 我把这个 这里有一个变化看到没有 在下面 100乘以10上面有一点点对吧,它有一个 被选中,就是它这个括号一直到 那里才结束,它这个 就是我们刚刚说的那个 分母下面的那个,根号下面的 一长串对吧,那因为我们 这里有选择,比方说这里选择就是 自我的SD对吧 然后平方,然后他人的 SD然后再平方 两个信号,2就表示 就表示你多少个幂次方对吧 就是多少次幂,然后 这个就是2对吧,然后减去 2乘以他们相关系数对吧 这就是他们相关系数,然后再乘以SD1 然后再乘以SD2对吧 然后到这里的话 它就是前面的一整个括号了对吧 看到 到这里的话,大家可以看到它括号 是最前面的了,就是 对应的就是我们公式的 类似于就是整个前面一节 对吧,然后后面加上一个校正的就是 根号下的2乘以 1减去他们的相关系数对吧 那这样的话我们就手动的运算 得到它的一个值 然后这里的话我们可以看到 这个是在我们的RMD 里面引用R的数值的时候 我们之前说过对吧,就在文字 在文字里面如何去引用 这个某一个 变量,那我们就在 间号一个R,后面就是加上这个变量名对吧 后面其实也可以加一个公式 什么都可以 这个没问题吧 然后大家 再算一算 还要给点时间,还可以算算 有人解除了? 都一样了吗? 1.2,你们呢? 1.233? 你们算出来了吗? 算出来了吗? 还没有 你们是多少? 还没算出来 那赶紧的 再算一下 要用R来写 写一写 不要用手机 用手机算一下 会用R写出来 ...... 有几个人用两种方式来算 ...... ...... ...... ...... 那我们我看一下 这个地方应该是不是还有更新啊 好我们待会儿先讲一讲 然后大家还需要花时间练习如何计算 benchmark因为我觉得我们就是把一个最核心的东西讲清楚之后,大家后面再看更复杂的时候,才知道自己到底在做什么。 然后我们讲一下这个语言分析啊,那么讲语言分析的时候,我们可以再回到刚才的之前给大家看过这个图对吧? 这个很有代表性的一个图,就是说假如你想象你自己做了一个研究对吧?你做了一个研究实际上下面是什么? 假如说在平地主义这个框架之下,我们会通常认为你真实的世界中存在某一个特定的效应量。 这就是我们在平地主义里经常看到的,就是你存在一个参数,某一个模式的一个参数。 就比方说,当你要去用平地主义的这个框架去推断你的治疗是不是真的有效的时候,你想做的事情, 比如说假如我们无数次重复你的治疗过程,那么一万次,那你最后可能有一万个效应, 那么最后这一万个效应,它会趋向于一个真实的情况,你的治疗方法是不是比没有治疗过程,其他的旧的治疗方法更有效率。 虽然说这个假定非常不合理,但是平地主义它就是这样一个假定。 那么也就是说我们的量体实验率有点像是我们在某个中国的效应上提供的一个。 那么假如说有很多人他们在同时在不同的地方做类似的一个实验, 我们是不是可以把这些效应拿过来,然后对它进行一个综合。 那么本质上的话,或者说如果是他们某种程度上都是关注着同一个效应的话, 那么我把它拿过来之后,那么我把它进行一个综合之后, 它应该能够得到一个对真实的更好的估计,对不对。 那么在统计过程当中是这样的,对不对。 所以就有了我们一个对效应量的综合的一个方法,那么就是我们这里说的一个原分析,对吧。 那么原分析它的本质上就是说,要把不同的研究,如果他们研究的是同一个效应的话, 我们能不能通过统计的方法把它综合起来。 那么理论上对多次采用的估计值进行综合的话,我们能够得到一个更加准确的一个估计对这个参数。 那么所以从这个角度来讲,原分析它就是一个统计的方法, 那么它就是对这个已经存在的多个效应量,我们通过统计的方法把它进行综合。 那么这个时候我们要对效应量进行综合的话,我们就需要效应量,对吧。 然后相关系数R或者是R, 那么同时我们也需要效应量的一个估计的误差,对吧。 就像是我们前面,大家可以看到我们前面在讲那个,在前面做那个, 讲那个CF的课,每一个估计对吧,它都会有一个误差。 那么我们要把它综合起来,我们这个误差肯定要考虑到一个地方。 假如你的误差很大的话,那么我们是不是应该对这个权重要放低一点,对吧。 这是一个最符合直觉的一个观念。 假如你的误差很小的话,我们应该给你更多的权重,对吧。 那么这样的话,我们把我们前面的信息,就能够更好的,就是去inform, 就是说对我们这个总体的这个参数值的估计进行一个相当于是一个调整,或者是一个regulate。 然后基本上样本一样,那么如果说我们要估计它的这个效应量的这个估计, 就是说它估不到误差的话,一般来说是看它的误差的量。 因为样本越大的话,你的采样误差越小,那么你得到的CF越精确。 那么这个实际上又回到了我们学统计的一个抽样的一个抽样分布的问题,对吧。 那你抽样分布的话,你的这个样比越大的话,你的这个SE就越小,对吧。 这实际上就是我们又回到统计学的一些基本的概念了。 如果大家对抽样分布比较熟悉的话,这个应该就非常熟悉了。 那么原分析的话,我们就是说通过,假如说我们知道原分析想干什么的话, 接下来都是技术的问题,对吧。 那它就是说通过什么样的具体的一些统计方法,能够把不同的效应量进行一个综合。 那么所以它会有一些,就比方说有一些综合的方法,比方说我们可以看到这个θ对吧。 那么θ就是wi,wi就是权重,就是权重,然后乘以它的这个yi对吧,就是它的一个效应量对吧。 本来就是说我们如何对不同的效应量,给它赋予不同的权重,做一个加成平均,对吧。 那么怎么去算这个权重呢? 那在不同的这个方法里面或者不同的模型里面,它会有自己的具体的计算公式。 那么很多时候对我们来说的话,我们其实可以,如果大家不想了解细节的话,也可以不用去管它对吧。 如果想了解细节的话,可以去看它这个权重到底是如何确定的。 那么一般来说传统的原分析模型的话,就是通过它的效应量的变异的大小的导数,来对它进行一个加权。 比方说你的标准差的平方对吧,然后对它的求导数,然后进行加权。 那么当然可能还会有一些其他的方法,这里就不细致的展开。 那么另外呢,就是说原分析它也是一种文章类型,我们之前也提到这个就是psychological quality,对吧。 那么psychological quality的话,实际上它的影响性是非常高的,如果说在一个发现的话,那肯定是非常好的。 从发现到现实当中,在心理学领域的原分析的数量其实是增长很快的。 而且原分析一般来说影响性也比较高,但是它有一个问题就是它在,它有的时候会被认为它不是实证的研究,可能没有太多的创新性。 那么我们接下来的话,可能会介绍一下关于原分析的一些具体的过程,但是在介绍很多这个过程之前呢,我想先就是展示一下我们如何在我们自己已有的这个数据中做一个,用R来做一个简单的一个原分析,做一个我们相信叫做prototype对吧。 如果说大家想想,如果原分析是对效应量综合的话,那也就是说只要有两个以上的研究,我们就可以进行原分析的。只要我们有两个实验,对吧,有两个效应量以及它的边缘,那么我们就能够做原分析,我们就能够对它的效应量进行综合,对吧。 那但是这是说统计上的一个要求,还有另外一个就是当你要想发表一篇原分析的文章的时候,它会有一些不同的要求,因为当你想要去发表一篇原分析的文章的时候,你想通过这个原分析去解决一个这个领域里面存在的问题,对吧。 那么你要想解决一个问题的话,就意味着你需要做更多的工作才能够去告诉大家,你确实解决了这个问题。那么一般来说,大家有一个很好的,很基本的一个要求就是,你这个原分析应该包括了一定数量的一个研究,对吧。 因为如果你不包括一定数量的研究的话,你可能你还是一个非常偏的一个研究。 比方说,举个例子,假如你想研究某一个效应,对吧,然后你就全部把你自己实验室的所有的研究数据拿过来,然后做一个原分析,然后告诉大家,你看那个结果非常稳定,非常一致,对吧。 但是大家肯定会怀疑,那你的这个研究都是在你自己的实验室的这个结果,对吧。那会不会带你去发展? 然后你会不会在研究效应的时候,你比方,基本上背试都是一个同志的背试,对吧,都是南师大的学生。 那么南师大学生会不会,他正好就有某一个我们不知道的一个特点,导致他在这个效应上面特别明显或者特别不明显,对吧。 那么这意味着什么呢?你需要去有更多的variance,对吧。你需要有更多的这种采样的空间,你才能够去说得到一个原分析,我这个原分析更加客观的。 更加公正的,更加不偏的一个工具,对吧。这样的话,你才能够帮助这个领域解决问题。 我们这里说的都是原分析作为一种文章类型,你要去解决一个领域的研究问题的时候,会有你更多的要求,但是原分析技术本身,它其实就是一个统计方法,你能够要做的其实很简单,我们就直接跳到后面去。 那么我们说一个简单的一个演示啊。假如说我们把这个数据分成两部分,对吧。 一部分比方说是有21个Base,一部分是有23个Base。那么21个Base和23个Base其实也符合我们心理学实验的常用的一个Base量对吧。 假如像今年我知道我们做每个实验只有20个,像原来也挺简单的,结果也挺还可以的,但是因为时间太赶。 但是我的意思是说20个人其实有的是我们心理学的实验经常会用的,那么我们现在就假定两个不同的人,或者说同一个人他做了两个实验,一个是实验EA,一个是实验EB,然后我们就在里面随机交给出两个Base把它分成两个数据。 这里的话其实有一些方法可能大家如果要做数据分析要做模拟的话,可能会经常会用到的,比方说我们去采样。这里可以简单介绍一下这里面用的代码,比方说我们首先把所有的独特的Base提取出来,对吧。 然后这里用的set seed就是我们要去把这个随机种子点控制下来,然后我们从这个subject list1,就是第一列Base的这个表,我们就是用sample这个函数,从所有的subject,就是上面的独特的Base里面,抽出21个Base出来。 那么抽出21个Base出来之后,下面是这个subject list1,它就是代表的所有的第一批随机被抽出来的Base,对吧。然后这样我们就可以从整个数据里面去获取一批样本。 就是把所有subject list1的Base调整出来,那么剩下的就是subject list2的一些Base。 那我们就通过这样一个很简单的方法,我们就把一个数据分割成两批数据,对吧。因为我们只是为了简单的演示这个原分析,所以我们就假定一个是时间1a,一个是时间1b,对吧。 那么我们的数据实际上就是从我们一个时间中抽取出来的。但是大家都理解这个逻辑吧,理解我们为什么要这么做的一个逻辑,对吧。 然后我们还是以刚才的这个效应量为例,对吧。然后我们比方说我们就计算出它的这个,跟刚才一样,对吧。 选出match条件下和good条件下面的这个自我和他人的数据,对吧。然后求均值和SD。 然后这个时候我们把它做了一个更大的一个,就是完了之后我们又把它进行了一个转换,转换成宽数据。 那么这个完全是为了符合后面的我们用metaphor包的一个需求。 然后我们把它重新命名,重新命名的话就是,就类似于是self, rt, mean,就是m就是match,对吧。 然后这个other,然后就把它变成一个宽的数据之后,这个好像下面还有代码,我还是转到那个,转到那个r里面吧。 好像不太能在这里直接看到。 这是我们刚刚讲的,对吧。我们可以就直接运行啊。这样的话可能更加方便。 大家知道这里面是什么,然后我们先看了subjects,对吧,我们可以把它打出来看看,它就是分割出了这个是所有的base,对吧。 然后我们在set seed1234,然后再去选一批base出来,对吧。 然后这样的话,我们选出了这批base,如果大家的r的版本跟我一样啊,而且都set seed跟我一样的话,这个时候我们选出来的base的这个needs应该也是一样的。 就随机的这个,虽然是有随机,但是它应该也是一样的,能够保证我们的可重性。 然后我们选出两批数据,对吧,这是我们刚才说的。 这个时候我们可以看到就是,这个里面就只有21个base,这个里面这个needs2就有23个base,对吧。 然后我们跟刚才一样把它做成,就是求每个条件下的总体的均值和SD,对吧。 前面到这里都是一样的,到这里ungroup之前都是一样的,但是我们后面把它进行了进一步的pivot,就是说进一步变成了一个宽的数据。 我们可以看一下两种条件上的区别。 比方说我们在这个ungroup这里,对吧,运行一下。 这个应该是list1,现在变量名有点长,它应该是长成这样。 然后我们可以再把它完整的运行的话,这个时候它就变成只有一行了,对吧,它变成这样了。 就是前面两个是它的均值,然后后面是SD,然后我们对它进行重新命名。通信密语之后的话它就会进一步的名字进一步规范化对吧 然后我们也去跟前面一样 就是说求出它一个宽的数据对吧 把它的自我和他人两组数据把它变宽 然后求它的一个相关系数 然后这个时候我们也可以看它的这个 简单查看相关系数0.228跟刚才是不一样的对吧 然后我们把它的在刚才的在这个list里面对吧 我们在后面增加两个值 一个是它的一个simple size对吧 因为做原分析的时候需要这个 然后我们再把它的这个ri就是它的相关系数加上 所以这样的话我们就会有这样一个data frame对吧 就是有两个条件的均值 两个条件的标准差 然后有它的simple size有它的相关系数 那么这就是我们对一个实验要做原分析的时候 我们所需要的全部的数据了 然后这相当于我们算出来第一个实验对吧 我们要计算效应量的时候的所需要的数据 比方说这个它的均值,标准差,simple size和相关系数 然后同样的话我们对这个第二个数据对吧 我们也做同样操作 然后这个就完全跟刚才一样的 只不过是把数据换了对吧 那么当然如果我们这里是复制了一次 然后改了一下变量名对吧 假如说我们复制两次或者三次的话 这个时候我们要考虑自己写一个函数 然后就不用再重复的复制这个过程了 然后我们同样把它变成宽的 然后再去做这个求相关对吧 然后我们同样的去把它变成一个 把它的样本量和它的相关系数放进来 这样的话我们就得到了另外一个对吧 这里也有一个 这个是就是list2对吧 就是第二个背是它的一个 这个是1这个是2 我们可以看到2的它相关系数0.4几对吧 然后它总共的333是23个 然后它的mean和st都是不一样的 那现在我们就得到了两个数据对吧 两个实验的数据 然后我们可以把它合并成一个数据框 这里很简单就是用这个rbind 就是说就是把这些 让他们以这个 就同样他们都有同样的column names对吧 然后我直接把它的rows就合并起来 那么这个时候我们用 这个地方应该是没有用的 这个代码要被做死掉了 然后我们可以用metaphor的escag 就是叫做effect size calculation对吧 然后来去算它的 就整个数据框去算它的一个effect size 为什么我们前面的数据框搞成那么一个形状 就是为了我们这里有这个mean1 对吧mei mri sd ei sd ri对吧 然后还有这个ni ri 就是我们把每个实验的这些相应的这些数据 都放到一个数据框里面 都放到这个数据框里面对吧 我们刚才已经都放这个数据框里面了 然后的话它就会帮我们得到一个 得到一个就是effect size 好没有metaphor metaphor是一个非常常用的一个包 它的一个开发者还定期会在网上搞那个直播 来告诉大家如何做原分析 大家如果感兴趣的话可以去看一下他的个人网站 是一个非常open的一个人 那么这个时候我们看一下这个 我们新算出来的这个 它长什么样对吧 这个地方我们直接在这看 我们可以看它就计算出来了 前面都是我们的刚才那个数据框对吧 一直到RI对吧相关系数 它后面就得到了两个 Yi和Vi对吧 Yi就是它的一个效应量 然后Vi的话就是这个效应量的一个误差 它的一个SE 那就是这个效应量本身的一个SE 那么我们刚刚说了其实 你要看一下这个地方对吧 计算的时候你到底用的是一个什么方法 就你这个方法到底应该怎么用 我们这里采用的是其他的 是这里的一个其中的一种方法 有的时候其实我们要看清楚 假如说我们要做得非常仔细的话 这些地方一定要看清楚它到底用什么公式 然后我们现在把它 就是相当于把它做出来对吧 然后Yi和Vi都引出来了 然后我们也可以比方说 让它再给它加一个columns 就是告诉它的一个名字对吧 那么我们这样的话 其实在后面加了一个unique ID 就是每一个相当于是第一个实验 它前面是第一个实验的对吧 后面是第二个实验的一个数据 那么这样的话我们就相当于是有两个实验 然后现在有两个实验的效应量对吧 还有它的一个自行区间 然后这样的话我们就可以做一个随机 随机的这个随机效应的一个游客系模型 然后很简单就是meta4对吧 然后RMA就是random model 这个meta analysis 然后Yi就是它的效应量对吧 Vi就是它的效应量的自行区间 然后data就是我们刚才这个对吧 所以我们就这么一个命令就搞定了 所以非常简单 那么这个时候它这里面 当然会给我们完整的一个 关于meta analysis的一个分析 我们可以看一下它这里面到底有啥 一般来说我们就把这个模型就放在这里对吧 然后它就会给我们很多的一些 比方说最直观的就是model result对吧 就是estimate 那这个时候它表示什么 就是说我通过对两个数据的综合之后 得到一个什么效应量 它的estimate是-0.6279对吧 然后S1是0.238 然后这个时候它会有z值p值和自行区间对吧 这实际上就是最后我们通过对两个实验 进行综合之后的一个综合的效应量 就是总体上的这两个之后的一个效应量 那么当然还有一些其他的 比方说它有一个关于heterogeneity对吧 就是抑制性的一个检验 那么抑制性的检验的话 它会有一些相应的指标对吧 然后就是说你这个研究到底是不是抑制的 比方说这里有个test对吧 然后说其实我们这个研究是没有抑制性的 那么这实际上是在做原分析 做一个文章的时候 你会去你需要去报告这些东西 但是有的时候我们只是为了综合效应的话 我们可能也不一定需要去报告这么详细 然后一般来说我们会画了 会给它画一个那个就是 我可以给它画一个这个森林图对吧 这是我们最常见的一个所谓的森林图 就是说你把这个不同的实验的效应量把它画出来对吧 那么我们可以看到就是 我们刚才通过自己的一个简单的分组对吧 分组之后我们就发现第一个实验比方 发效应其实就发进去 发效应比较小 然后0.43-0.43 然后大概就是说 我们自己实际上是一个单一的配对 然后另一半的数据的话 它就是效应量很大 基本上是前面的一个两倍 然后综合之后它就是一个SETUP 就是它这个REMOTE 就是RUNWAY FACTORY MODE 然后这个RUNWAY FACTORY MODE 一个一个 然后现在通过这种方式 它就能够可触化了 当然这是一个最简单的可触化 当你要出版的时候 当你要发表论文的时候 可能你还会想着 我如何把它变得更加漂亮对吧 这是一个很正常的一些想法 那么在METANANALYS结果作图方面 其实有很多的 目前有很多相应的一些作图工具 但是也不难 这就是我们一个最简单的 一个METANANALYS 就两个实验对吧 大家可以看到 我们在刚才展示 这个最简单的METANANALYS的时候 其实大家已经发现有很多细节对吧 比方说我们前面讲 效应量剧转的时候 就有这叫CONSTING 你有什么故事对吧 然后比方说我们这里说 我们这个实验有效率 我们这个实验有多少个效率 我们是2乘2乘2乘2的一个实验对吧 八百条 八百条就已经 如果说你没有任何的 发言的方式 没有任何的知识的话 你的两样组合就是C8R 就是C8R的效应 就是多少 就是28个效应 所以你从这28个效应里面 你选择哪个效应 报告 本身就是带有很多细节 对吧 然后你如何用什么来计算 这个有一定的主要性 比方说CONSTING对吧 CONSTING的话 我们是用原始数据来计算的话 我们自己现在是完全是 全手动对吧 就是全手动的算它的 并行ST 然后它的相关系数 然后把它 然后到最后算那个 effect size的时候 我们没有手动 我们正式用的是那个 MetaTorch里面的一个 ESTAP 就是ES Effect Size Calculation 那个函数来算 大家可能刚才都没有留意 我们前面实际上得到的是什么 就是每一个条件下的 我们可以看到是每一个条件下的 这个均值对吧 和ST和它的Sum Size 还有它的相关系数 然后我们后面这个 Effect Size实际上是通过 MetaTorch里面的这个 函数来算的对不对 那么如果我们自己手动的算 之后把它输入进去 那可不可以呢 也是可以的 那个Yi和Vi 我们可以自己手动去算 那么大家想想 如果我们真的做原汇区的时候 你可能不一定有原始数据对吧 你最后只能依赖于作者报告 均值ST 那么有的时候它报告均值ST 它不报告这个相关系数 那你这个相关系数 你还得手动的去输 那么有的时候 甚至它的均值和ST都没有 它只有一个P之后 你才能输 那这个东西怎么办 所以大家可以想象 这里面有不数位式籍 所以说MetaAnalysis 你要真想做的话 它其实就是一个 高式籍的一个东西 当然你需要首先知道 它是一个程序上的作者 这是MetaAnalysis的一个 就是我们看到了 因为R代码展示了一个 一个Prototype对吧 就是一个 圆形式的一个MetaAnalysis 然后我们刚才讲的就是 你真的做MetaAnalysis的时候 会有很多这种细节和困难 然后还要讲的就是说 你 我不做这种大型的分析对吧 那么我会不会 也通过MetaAnalysis 对自己的研究有用呢 这个是那个 一个华人的研究者 他 这样的美国 他之前在国国之间 他发了一篇评论 mini meta 就是讲 我单个研究对吧 我一个实验室的人 我就 我也不需要做很多这种 发言 我 我也不想把很多这种问题 都抓过来 但是我希望的 对我手头上这些实验 我就做一个效应的工作 这样起码比我一个实验会 一个实验会更准确对吧 那么这样的话 我们就会把手头上这些实验呢 做一个MetaAnalysis 然后它叫做mini metaAnalysis 那么这个mini metaAnalysis 它也会帮助我们去 更好的去估计 这个效应量 那比方说大家可以看到这个地方 我们做了这个随机效应过程对吧 就是做了这个接口 它的这个CR 它可能比上面两个CR 任何一个都要高 我不知道大家 在视觉上应该就可以看到对吧 就像是说我们 即便比方说你 有一个预实验对吧 你收了20个人 然后你发现效应 其实呢 有那么一点 但是不是那么显著对吧 然后你又做了一个正式的实验 收了40个人对吧 那你可不可以说把 前面的20个人预实验的数据 和后面40个人的数据 把它凝综合呢 如果说你是完全凝固了 完全可以通过 Mini Meta-Times的方法 把它综合起来 这样的话实际上你的效应量 你的样本量就是 增加到了60个人对吧 你也把你的这个 手头上这个数据叫做 Every Case 这样的话其实对自己是 你的这个效应量到底稳不稳定 是一个更好的一个 一个判断 反正Mini Meta-Times 它有的时候 它会有自己的一个问题 就是说你要 你要把自己的所有的 实验结果都综合起来 你不能只把写作的综合起来 你只把写作的综合起来的话 它效应就高估了 然后我自己在我的 这个博士论文里面 其实也用到了这个Mini Meta-Times就是把我自己做了一系列的实验的效应进行的一个综合,这样的话其实能够得到一个更加准确的判断。 你说。 很多实验它都有一些其他的变量,不是完全一样的。 对。 这个时候,你会自己会就,这个就是一看你的这个效应,就是关键的效应是什么,就像我们计算效应量的时候, 你看我们这两个实验,在计算效应量的时候,我们计算了什么,next, good的效应量,自我和它的一个差别。 假如说你一个实验比,比方说你是这个next, good,然后再加了一个什么其他的, 然后第二个实验你又换了一个,比方说你换了一个任务,或者你把它呈现的顺序改变一下, 或者你把它这个比方说刺激的,以前是视觉通道,现在是听见通道对吧。 比方说你的不同的实验,你看加了很多不一样的,但是你的这个条件,或者说你关注这个效应本身还是那个, 你就可以一直用这个效应来去把它说为mathematics。 但是有的时候,这个你要是,都是这个boot的byte,然后有的它内因素, 那你这样的话,你这个boot的byte它也是说内因素,但是你这里面是一个byte,这样的话。 那也没关系,也可以。 会。 相当于是说,对这种额外的质别你怎么考虑它,你认为它是不是某种程度上是一种, 每个实验它自己独特的这种随机性的一个影响。 如果你认为是可以把它当作这种随机性的影响的话,你就可以做mathematics对它进行综合。 对。 那么有个什么好处呢,比方说做这个综合的时候,其实对我们下节课讲的power analysis是非常相关的,就是, 假如说你根据一个研究的这个,估计去做power analysis的话,肯定没有根据这个比方说minimathematics的效应来去做power analysis。 因为这样的话,我就是结合了更多的数据的。 还有什么情况,我可以就大家问一下,比方说我们做的这个,有可能是,这个是之前有一个JPT的主编写过一个,他自己神秘的搞定了。 假如说我们就跟这里画一个类似的图啊,这个地方是0对吧,然后假如说我们的实验1是在这儿, 然后实验2在这儿,然后大家想想,如果说我们做一个IE模组的话,它的结果可能会在哪儿? 它的结果可能就会是这样。 这个地方很明对吧,也就是说你的两个不显著的实验结果,你做一个mimathematics,它也有可能会显著。 为什么呢?因为这两个实验它的结果方向都是一致的。 搞错了,说错了。 我想演示的是这个,这个意思,不好意思。 就是你的两个实验,可能因为各种各样的原因,可能就是它的噪音比较大。 但是你的效应要的中心点都是在小于0的。 这个时候你通过两个实验的综合的话,你可能会得到一个结果,就是说它可能就在这附近。 但是呢,它的CI会更小一点。 明白吧,因为你把数据综合到一起之后,它的误差就会变小了。 它就可能会完全站在你的左边。 明白吧,所以这可能是大家最期待的一种mimathematics出现的结果对吧。 我有两个不显著的结果,但是我做了一个mimathematics之后,发现它显著。 当然这要依赖一个特定的情况,就是说你的这两个都是, 它都是,就是说,稍微比方说只是稍微挡平包围,对吧。 绝大部分其实都是可能都在0的,它CI比方说都是在0的一边的。 它的效应要的方向是一致的,这种情况下的话,你就可能能够得到一个, 把两个不显著的结果得到一个显著的结果。 或者像我们这里对吧,一个显著的结果,一个不显著的结果。 它分化之后,只能得到一个CI更短的一个显著的结果。 那如果大家对原分析感兴趣的话,我觉得,我个人觉得最好的办法, 你就是找一个checklist。 就现在有很多这种原分析的检查清单,大家不要觉得做原分析是没有资料可循的, 其实有很多资料可循,因为做原分析已经是一个非常成熟的套路了。 我们所要关注的就是你照着这个套路,然后把里面的细节, 每一个做的非常的扎实。 那么我应该是去年还前的时候,我们那个当那个工作很早了, 就是我在读博士开始了,就是跟国内一些都做过meta analysis的人, 我们一起写了一个关于就是报告原分析文章的一个规范。 就是在那个文章里面,我们提出就是你要去报告原分析的哪些部分, 这样保证你的原分析是比较规范的,比较容易被重复的。 那么在那个文章的附件里面,我们有一个检查清单, 那个检查清单基本上你就可以对着一条一条的去对, 我做原分析我要去做什么,就一条一条去对就可以了, 方法部分,结果部分,然后对完了,你把它每一条都做出来, 基本上就可以保证你的原分析做了一个就是步骤是完整的。 那个文章是发表在这个中国科学生命科学上面, 大家有机会可以去看看。 那接下来的话,我大家可以我看一下还有还有大概半个小时啊, 我们也再做一个简单面试啊,刚才大家不是计算了这个, 就是自我调教good和bad吗? 大家看能不能同样的就是做一个good和bad, 然后做一个简单的meta analysis, 自己能够去把这个数据也进行分组, 最好你可以按照自己的房子进行分组, 然后你可以一组分15个人,另外一个分29个人, 然后把平均的去计算它的这个下半段, 然后它的这个做一下综合做一个随机性的结果。 明白我的意思吗? 大家笑什么? 代码都在这啊,代码都在这。 可能在GitHub有一个不一样的吧, 你去飞机上, 你去GitHub的云点之后啊, 我把这边关一下。 稍等一下,我这边连一下网。 我这个电脑没装GitHub,所以没办法上传。 我这个电脑没装GitHub,所以没办法上传。 我这个电脑没装GitHub,所以没办法上传。 我这个电脑没装GitHub,所以没办法上传。 我这个电脑没装GitHub,所以没办法上传。 我这个电脑没装GitHub,所以没办法上传。 我这个电脑没装GitHub,所以没办法上传。 我这个电脑没装GitHub,所以没办法上传。 我这个电脑没装GitHub,所以没办法上传。 我这个电脑没装GitHub,所以没办法上传。 我这个电脑没装GitHub,所以没办法上传。 我这个电脑没装GitHub,所以没办法上传。 我这个电脑没装GitHub,所以没办法上传。 我这个电脑没装GitHub,所以没办法上传。 我这个电脑没装GitHub,所以没办法上传。 我这个电脑没装GitHub,所以没办法上传。 我这个电脑没装GitHub,所以没办法上传。 我这个电脑没装GitHub,所以没办法上传。 我这个电脑没装GitHub,所以没办法上传。 我这个电脑没装GitHub,所以没办法上传。 我这个电脑没装GitHub,所以没办法上传。 我这个电脑没装GitHub,所以没办法上传。 我这个电脑没装GitHub,所以没办法上传。 我这个电脑没装GitHub,所以没办法上传。 我这个电脑没装GitHub,所以没办法上传。 我这个电脑没装GitHub,所以没办法上传。 我这个电脑没装GitHub,所以没办法上传。但是坦白讲就是metanalyst本身是一个很复杂的一个东西啊,包括 都有好多书是专门讲这个东西的,所以我们也不可能 一堂课就把它全部讲清楚,我们只能说把它的最核心的 这个统计的东西讲清楚。 再打开这个。 大家直接跳到,如果说要重复这个的话,就是做这个练习的话,大家直接跳到 应该是那个有一个叫做简单的一个简单的 原分析这里,简单的演示这里。 原分析步骤8以后简单的演示这里,这个地方就是开始 我们刚才演示这个代码部分,大家做练习的话也从这部分开始 大概是第365行。 那在Github上面也可以直接打开就可以看到了,如果能打开的话不用再下载下来。 因为如果大家要去完成这个练习的话,其实还是要抄代码,抄代码的话,你在Github上面也可以抄代码。 最近我非常开心看到这么多的开心Github。 加速中... 谢谢 大家可能有的看到后面的代码还说有些报错对吧 大家可以看到我们代码到把这个简单的模型展示完了之后 后面的很多代码都是不跑的呀 大家如果看到我们有一个evaluation等于force 就是说evaluation等于force就是不跑这些代码 为什么因为这个RMA 尤其是后面的RMA基本上都是为了出于演示的目的来展示的 这是我们之前助教准备的一些代码 但我觉得可能这个东西太多了 所以大家可以这么认为 从forest后面的470行以后的代码 如果大家要跑的话自己要跑一个完整的 最好是更多研究的一个Metaverse在区域 要不然的话显示不了实际上的 显示不了实际上的一个结果 470行以后的代码大家可以忽略 暂时可以忽略 我们后面可能会把它删掉 因为这个内容你要去Metaverse的官网里面也找 这些代码也可能会找不到 我们今天这几个实际上就是演示下最核心的 Metaverse最核心的一个部分 有人把我们刚才说的这个意思做出来了吗 你们 没有 大家如果感兴趣的话还可以看一下 我算了一下 把练习完成的人不多 但是好像我们上课的时间也没有了 这个就比较麻烦 我在想我们第三次做小作业 我们应该有三次小作业 第二次小作业可能还没有完成 第三次小作业我想大家看是 我有两个选项大家来选 选一下 一个选项就是我们今天学的这个Meta-Analysis 然后大家去把这个数据 我们的 就是这个数据是我们提供给大家的 它实际上是我在 我自己的一篇文章里面的CNR 如果是把这个作业 就是把原来那个数据里面的CN1的数据找过来 把CN2的CN1做一个Meta-Analysis 做第二次的 做三次小作业 这是一个选项 第二个选项是练习上次的 APIA那个 就是那个从 从那个数据转成PDF 生成PDF是搞定 大家可以选想选哪一个 Meta-Analysis它是选生成PDF 啥 啥 都不选 都不选 那总得有一个作业 我们这个有三次小作业 总得有一个第三次小作业 第二次小作业是练习GitHub的操作 对吧 这个其实很简单 基本上没有什么挑战 那么第三次的话 就是我们现在 因为我今天接到消息 就是说我们课差不多就是今天 这一次 然后下周还有一次 然后16号那一周就开始要安排考试了 基本上就是我们要准备给大家 那个时间做大作业了 明白吗 也就是说我们现在 今天是倒数第二次课 下一次就是最后一次 我讲课的内容 然后在下一次 16号那一周的话 就是没有给大家去做大作业 因为要是一节课都不给的话 就做不了大作业 就是考试周的时候 你要汇报大作业的时候 就打汇报 小作业它就 我觉得好像比较简单一点 就是比这个Takiyah的Sensor PDF 会简单一点 因为那个它会涉及到 R语语言以外的一些东西 特别是那个NetTag 一些东西 可能会比较复杂 而且如果让每一个人都做的话 可能会困难更大一点 那要不就这样 就是说大家第三次小作业 就是下载 下载我那个文当中的 实验1的数据 然后就把我们 这个展示在这里的 比方说这个方法 就是在Nets条件下面 固定条件下自我和他的差异 我们在这里已经展示出来了 对不对 大家把另一个部分 数据下载下来 然后做一个预处理 然后跟它一模一样 然后把它 就是做成一个Metanames 然后画一项Floss就可以了 OK 但是大家需要注意就是 我们还是要做一点改动的 我们真的是把这个数据 分割成两部分了 大家千万不要在大作业的时候 也把它分割成两部分了 这个就把它当做一个实验的结果 然后把预实验的 把那个公开数据中的 另外一部分数据 预实验的数据拿过来 大家相当于是需要去复习一下 这个预处理的一个情况 然后大家每个人提交一个 提交一个RMD文件 跟之前一样 跟第一个小作业画图一样 是一个RMD文件 RMD文件需要放到 我们现在这个文件夹里面 就能够运行 也就是说大家的相对路径 要使用相对路径 对吧 还记得相对路径吗 就大家要在这个文件夹里面去运行 然后发送一个RMD文件 然后可以到时候提交了 在下下周之前提交 OK 然后大作业的话 我们也提前给大家说一下吧 大作业的话大家去 Psychological Science Forecastation Nature Human Behavior 或者Nature Communications 或Science of the World 这四个期刊 我们就四个期刊 四个期刊上找到 有公开数据的文章 然后把它的分析 把它reproduce一遍 不用完全reproduce 选择一个你最感兴趣的项目 给它进行一个reproduce 然后大家需要 现在大家一定要回到小组 现在小组可能有时候 好像已经没有小组存在了 大作业是以小组为单位完成的 大家要开始讨论和准备了 然后大家需要交几个东西 第一个就是一个文档 这个文档考虑到这个Papier 可能大家难度太大了 大家可以过了文档还行 也可以直接Papier准备 推荐Papier准备 然后这是第一个文档 第二个就是报告 大家可以我们再选一周来去 不一定是周一 到时候我们可以协讨 考试的时候大家决定 就是选一天来进行一部汇报 每个小组就要汇报自己的 就像做研究展示一样 汇报一下自己的分析图 这是reproduce的一个结果 也要选前言、方法、结果 前言的话就是 它的背景是什么 你为什么要选它 方法就是你过后来复制 它做了什么方法 你需要展示一下你的态度 然后前言的话 你就觉得你复制的结果怎么样 回到结果体里 然后讨论你觉得怎么样 这是一个正常的文档汇报的过程 把自己的重复的过程成为一个结果 第二个部分就是展示 第三个就是代码文件 代码文件的话就是一个RFQ文件 那么这三个内容构成了 大家每个小组最终的大作业的内容 OK 有什么问题吗 这个小组要开始 以小组的这个 做一个整体来工作了 那我们今天就到这里 第三次小作业和最后大作业 都已经公布开了 然后选课的同学一定要认真对待