---
editor_options: 
  markdown: 
    wrap: 72
---

# 第九章：如何进行基本的数据分析: 中介分析{#lesson-9}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # Wickham的数据整理的整套工具
pdf.options(height=10/2.54, width=10/2.54, family="GB1") # 注意：此设置要放在最后
```
## process
今天我们会讲解SEM的一些简单的操作和画图，画图的部分甚至可以掰开讲：怎么画一个直方图怎么画一个展示反应时的图，箱线图和小提琴图，以及云雨图。

在接下来的课程中，第11章想要达到一个目标是我们的能够做出来图可以符合格式，大家投稿的时候就可以直接用。第12章的话实际上就是把第10章和第11章的内容进行结合，我们会教授一个papaja包，这个包适合我们APA格式的一个写作。如果我们能够把自己的代码和数据和文字全部整合到一个东西里面去，这样的话就可以直接生成一个APA的手稿，这是12章我们想介绍的。第十三章我们原本想讲github的使用，但是考虑到github可以在后续的学习中反复使用练习，我认为可以移动到下周来讲，然后第14章有一些干货的内容，比如如何对效应量进行综合，这是在meta analysis常用的工作如何进行样本量的规划，这里面最重要的是power analysis。

这里面可能还会涉及到一些大家以前从来没有——至少我在读研究生的时候从来没有的一个东西就是我们如何在计划研究的时候就把整个代码写出来。我们一般来说是自己先有了数据，然后再去写代码，我们现在我们课题组慢慢的做法是变成一开始就做预注册，做完预注册了以后，就会自己开始写一些伪数据，我们叫假数据，它的结构是跟我们的实验的设计是一模一样的，那么这个时候我们就开始用这样的假数据把自己分析数据的代码就写完，也就是在你没有收集数据之前， 就可以把代码写完。

其实我用SEM用的很少，主要都是认知心理学舒颜，神经成像之类的东西，很少去做问卷相关的研究。但是我其实对传统的SEM很感兴趣。这里推荐一些经典的文章，比如Baron和Kenny1986年关于中介调节分析的文章。
那么process是Andrew Hayes，引进的一个很重要的一个工具包，这个工具包某种程度上解放了绝大部分人，他的引用量也非常高 那么process这个SPSS插件出来以后，应该是给很多人都非常大的帮助。
是2012年左右的时候，他开始还是小的一些工具包，后来就变成了一个插件，后来就越来越好用。大家可以看到， 整个R的这个生态体系 它其实是一个后起之秀，即便如此 因为R是一个开放的生态系统 所以只要有足够的人对它感兴趣的话 很快它就能够迅速的发展。


首先是导入这两个包，我们用之前一样的方式来去安装，我建议大家就是现在在讲课的时候，如果手头上有这个代码的话 可以把这个地方先运行一下，因为你可能需要安装新的包。
```{r pacakge, echo=TRUE, message=FALSE}

# 检查是否已安装 pacman
if (!requireNamespace("pacman", quietly = TRUE)) {
  install.packages("pacman") }   # 如果未安装，则安装包

# 使用p_load来载入需要的包
pacman::p_load("tidyverse", "bruceR", "performance", "lavaan", "lavaanPlot")
```
导入我们的数据
```{r get socialdiversity, eval = FALSE, echo = FALSE}

df.pg.raw <-  read.csv('./data/penguin/penguin_rawdata_full.csv',
                       header = T, sep=",", stringsAsFactors = FALSE) 

snDivNames  <- c("SNI3" , "SNI5", "SNI7" , "SNI9" , "SNI11"  , "SNI13",  "SNI15", "SNI17","SNI18","SNI19",
                "SNI21")
extrDivName <- c("SNI28","SNI29","SNI30","SNI31","SNI32")    # colnames of the extra groups

### get data for diversity
snDivData <- setNames(data.frame(matrix(ncol = length(snDivNames), nrow = nrow(df.pg.raw))), snDivNames)

### recode spouse/partner Q10 (spouse): 1-> 1; else ->0
snDivData$SNI1_r <- car::recode(df.pg.raw$SNI1,"1= 1; else = 0")

### re-code Q12 ~ Q30: NA -> 0; 0 -> 0; 1~10 -> 1
snDivData[,snDivNames] <- apply(df.pg.raw[,snDivNames],2,function(x) {x <- car::recode(x,"0 = 0; NA = 0; 1:10 = 1;"); x}) 
colnames(snDivData[,snDivNames]) <- paste(snDivNames,"div",  sep = "_")   # add suffix to the colnames

snDivData$SNIwork   <- snDivData$SNI17 + snDivData$SNI18                  # combine the diversity of work (SNI17, SNI18)
snDivData$SNIwork_r <- car::recode(snDivData$SNIwork,"0 = 0;1:10 = 1")

### re-code extra groups, 0/NA --> 0; more than 0 --> 1
extrDivData <- df.pg.raw[,extrDivName]  # Get extra data

### sum and recode the extra groups
extrDivData$sum <- rowSums(extrDivData)
snDivData$extrDiv_r <- car::recode(extrDivData$sum,"0 = 0; NA = 0; else = 1")

### combine the recoded variables
snDivNames_r <- c("SNI1_r","SNI3","SNI5","SNI7","SNI9","SNI11","SNI13","SNI15","SNIwork_r",
                  "SNI19","SNI21","extrDiv_r")

### get the social diveristy score
snDivData$SNdiversity   <- rowSums(snDivData[,snDivNames_r])

### save the social diversity index
df.pg.raw$socialdiversity <- snDivData$SNdiversity

rm(extrDivData, snDivData, extrDiv_r, snDivNames, snDivNames_r, extrDivName)
write.csv(df.pg.raw, "./data/penguin/penguin_rawdata_new.csv")
```
```{r WD & df.pg.raw}

df.pg.raw <-  read.csv('./data/penguin/penguin_rawdata_new.csv',
                       header = T, sep=",", stringsAsFactors = FALSE) %>%
  dplyr::select(., age, language, avgtemp,socialdiversity, DEQ,
                   starts_with("ALEX"),
                   starts_with("ECR"),
                   starts_with("HOME"),
                   starts_with("KAMF"),
                   starts_with("SNI"),
                ) 
# 这些包含原始题目的数据集，将在SEM lavaan中直接使用
```
```{r df.pg.raw DT, echo=FALSE}
DT::datatable(head(df.pg.raw, 10),
              fillContainer = TRUE, options = list(pageLength = 5))
```
刚才助教应该发给大家 大家把它保存在我们原来这个data Pangolin里面 然后叫Pangolin raw data new 为什么用这个新的数据呢 因为它这里面是有一个 有一个新有一个变量 我们原来那个数据里面没有包含 那么假如我们对某几个问卷感兴趣 我们就把它都选出来 然后把其他的这个变量都忽略掉 那么我们这里大概就是要做两个工作 一个工作就是我们要演示两个工作 一个工作就是我们重复一下 艾特曼在2018年发表的 Clever Psychology那篇文章中的一个分析 也就是我们这个数据来源 Pangolin的数据来源 它本来就是在2018年那个文章中 是以最主要的一个研究性的文章对吧 那么我2019年那个文章 实际上是把这个数据进行一个描述 那么第二个工作就是说 我们可不可以对一些问卷来 对它的这个问卷的结构进行一个确认 那么采用CFA的方式 那么或者我们对不同的问卷进行的关系对吧 有没有这个中介调节 采用ICM的方式来做一个分析 这大概就是我们要展示的这几个工作 这个地方是一个数据运输里的过程 就是我们怎么去求 那么在这个 我们这次增加里面不仅仅有一个 我可以给大家看一下 我们这个数据里面 不仅仅增加了一个 就是叫full data 还有一个new data 这个new data是我们对full data进行处理的 然后还有一个codebook 就是关于这个应该是最 就是数据最全的一个 但是它都是原始数据 这个是最全的一个数据 那么刚才孟征发给大家那个 亚述包里面应该有 那么我们还有一个codebook 就是对这个数据本身的一个描述 这个数据它的每一个column 代表的是什么东西 那么这里的有一些数据是没有的 我们把它给去掉了 因为它可能涉及到背后的隐私的问题 那么这里会涉及到一些问卷 比如说这个叫做Alex 它实际上是一个关于 那个肃清障碍的一个问卷 它的这个参考文献是在这 就是叫做Toronto Laximedia 这个我还不知道什么 Alex Thymia Scare 然后这个ERC是关于这个情绪的 和attachment的一个问卷 这个home就是说对家的依恋 是一个互联网出现以后 也不是互联网出现 就是也是一个跟这个依恋相关的一个问卷 那么这个KAMF是一个新的问卷 它实际上是关于人的 会不会产生这种感动的一个情绪 那么我们就是说在process里面 它实际上是一个简化的一个SEM 它只需要对我们变量的题目内部求一个平均分 然后这样就可以了 那么它不需要去了解 这个每一个问卷里面的item 和它的维度 以及和整个问卷是不是有对应的 以及它的loading是什么 那么为什么说它是一个简化的模型呢 这里可能涉及到一个问题 就是说我们到底 当我们用总分代表一个量表得分的时候 它代表的到底是什么 它实际上代表的就是每一个item在这个 维度上面的loading完全是1对吧 它完全是相等的 这是一个非常强的assumption 然后也是一个非常简化的一个模型 那么通过SEM的一些CFA的分析的话 我们其实可以更好的估计它在每个潜变量 就是我们的一个问卷它可能是一个测量了一个或者多个 潜变量的一个问卷一个工具对吧 那么当我们用总分代表一个 潜变量或者一个维度的得分的时候 我们认为所有的item在维度上面或者潜变量 上的loading对吧 这个负荷都是1 但是用LCM的话我们可以把更加精准的建构出来 对于假如说我们要用process对吧 那我们就直接就把每一个维度上的得分求出来 当我们这里没有用process 我们用process没有做他们这些问卷的一个处理 而是去复制了Pandroid data里面的结果 感觉我应该需要展示一下原来那个论文才对 一会儿增加一下 那么在原来这个论文里面 它大概就是有这么一个关系的一个结果 那么我可以简单的跟大家说一下 我们这个项目对吧 原来这个数据项目叫做Human Computing Project Computing是什么是企鹅对吧 人类企鹅计划 它为什么要起这么一个名字呢 它就是觉得我们人类就像企鹅一样 有一个共同的一个体温调节 因为企鹅它生活在一个非常寒冷的地方对吧 它经常就是为了降低它取暖的能耗 它会很多企鹅在一起群聚到一起 这样的话就是说每个在一群里面 每个企鹅它都能够保持着一个相对恒定的体温 但是对于这个群体当中的每一个个体来说 它的能耗是比较小的 大家知道我们要维持一个恒定的体温的话 我们是要去燃烧一些卡路里对吧 那么如果说我们只有一个个体的话 它维持一个恒定的体温所需要的卡路里是非常多的 这样对于人类来说 现在好像卡路里是一个多余的东西 但是对于动物来说 当你在野外的话 其实你要去获得能源获得食物 本身就是一个有动物意志在做的一个事情对吧 所以它需要去尽量减少这个能耗 所以它就会在一起形成这么一个机制 那么这个Human Pending Project想说 就是说我们在人类的身上是不是也找到这种 我们做哺乳动物在演化当中形成的这种 群体体温条件的一些我们说一些traces 就是我们在演化当中 我们现在在现代化社会里面对吧 但是我们的身心上面可能还是遗留了一点点 我们原来做哺乳动物 通过群体来调节我们体温的这些遗迹对吧 所以这是这个项目的一个总的一个大胆理论 那么在这个过程当中 它做了一个什么工作呢 就是测量了很多问卷 并且测量了每个人的一个核心体温 这个核心体温就是说我们自己 Cold Body Temperature 这个时候在文章里面它是用CDP 就是Cold Body Temperature 我们这里是用Belian Temperature 就是Average Temperature 那么这个Cold Body Temperature是什么 就是我们身体核心所需要的一个温度 身体的核心是哪些呢 基本上就是内脏对吧 也就是说我们如果内脏不能够保证 这个恒定的体温的话 基本上就会直接影响到你的生命的安危 包括你的大脑 所以对哺乳动物来说最重要的 其实有的时候像比如说手对吧 你的手和脚 它即便失温了之后 它可能也不会影响你的生存 然后可能手动坏了对吧 有的人他比方说就结织掉了 那么它是会影响 但是它不会影响生存 它还是可以继续活下来对吧 但是如果你的核心体温 如果你不能保持恒定的温度的话 那就就是30的一个问题了 所以最感兴趣的 就在这个语言内容中 最感兴趣就是核心体温的温度 那么我们想如果说想要知道这个人 他我们人类上是不是遗留了这种 群体调节体温的遗迹的话 那我们应该关注的是什么 就是我们的社会关系对吧 你跟社会群体关系相关的一些变量 它会不会影响体温 这就是他最关系的 Hans Eisenberg最关系的一个问题 所以当时他测了很多跟社会关系 社会网络相关的一些变量 就比方说你有 你在过去的一个月当中对吧 你跟多少人联系 然后你比方说平时上班的时候 跟多少人联系 下班之后跟多少人联系 周末跟多少人联系 跟你的父母 跟你的你是不是跟你的 比方说partner对吧 住在一起等等 就有很多这样的问题 那么通过这个问题 他可以得到三个 社会关系网络的一个指标 一个指标就是叫做social diversity 就是你的社交网络 是不是很多元化 还是说你的社交网络就很单一 然后你就只跟父母 跟家人交往对吧 那你的这个社交网络就很单一 然后你有家人有同事 然后还有你自己比方说 你有很多个兴趣爱好对吧 你跳舞有跳舞的朋友 你唱歌有唱歌的朋友 然后你下棋有下棋的朋友 然后等等等等 如果说你的这个 关系网络非常的 就是不同的 在不同的场合跟不同人交往对吧 这样的话就会形成一个 很diverse的一个social network 那么这个social diversity 就指的是这个东西 然后他也测量了比方说 你的身高体重等等等等 然后还测每个人他和赤道说 隔的这个距离 the distance from the equator 就是你赤道这个距离 因为你赤道隔得越远的话 就意味着你这个纬度越高对吧 纬度越高 就意味着当地的气温本身是越低的
