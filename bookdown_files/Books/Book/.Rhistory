hit / (hit + miss),
1 - 1 / (2 * (hit + miss))
)
) - qnorm(
ifelse(fa / (fa + cr) > 0,
fa / (fa + cr),
1 / (2 * (fa + cr))
)
)) %>%
dplyr::ungroup() %>%
select(-"hit",-"fa",-"miss",-"cr") %>%
dplyr::group_by(Sub, Shape)  %>%
tidyr::pivot_wider(names_from = Shape,
values_from = Dprime)
bookdown::publish_book()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # Wickham的数据整理的整套工具
pdf.options(height=10/2.54, width=10/2.54, family="GB1") # 注意：此设置要放在最后
install.packages("bruceR")
library(bruceR)
library(dplyr)
library(tidyr)
WD <-  here::here()
df.pg.raw <-  read.csv('./data/penguin/penguin_rawdata.csv',
header = T, sep=",", stringsAsFactors = FALSE)
DT::datatable(head(df.pg.raw, 10),
fillContainer = TRUE, options = list(pageLength = 5))
df.pg.mean <- df.pg.raw %>%
dplyr::filter(sex > 0 & sex < 3) %>%
dplyr::mutate(ECR_mean = rowMeans(select(., starts_with("ECR")),na.rm = T),
HOME_mean = rowMeans(select(., starts_with("HOME")),na.rm = T),
sex=as.factor(sex)
) %>%
dplyr::select(sex, ECR_mean, HOME_mean, Temperature_t1,Temperature_t2)
bruceR::TTEST(df.pg.mean, "HOME_mean", test.value = 3.5, test.sided = ">")
bruceR::TTEST(df.pg.mean, "HOME_mean", test.value = 3.5, test.sided = "<")
result.ttest <- capture.output({
bruceR::TTEST(data=df.pg.mean,
y="HOME_mean",
test.value = 3.5,
test.sided = "=")
})
writeLines(result.ttest, "./output/chp7/single_t.md") # .md最整齐
bruceR::TTEST(df.pg.mean, "HOME_mean", test.value = 3.5, test.sided = ">")
bruceR::TTEST(df.pg.mean, "HOME_mean", test.value = 3.5, test.sided = "<")
result.ttest <- capture.output({
bruceR::TTEST(data=df.pg.mean,
y="HOME_mean",
test.value = 3.5,
test.sided = "=")
})
writeLines(result.ttest, "./output/chp7/single_t.md") # .md最整齐
result.ttest <- capture.output({
bruceR::TTEST(data=df.pg.mean,
y="ECR_mean",
x="sex")
})
writeLines(result.ttest, "./output/chp7/inde_t.md")
bruceR::TTEST(df.pg.mean, "HOME_mean", test.value = 3.5, test.sided = ">")
bruceR::TTEST(df.pg.mean, "HOME_mean", test.value = 3.5, test.sided = "<")
result.ttest <- capture.output({
bruceR::TTEST(data=df.pg.mean,
y="HOME_mean",
test.value = 3.5,
test.sided = "="
file = "./output/chp7/single_t.doc")
bruceR::TTEST(df.pg.mean, "HOME_mean", test.value = 3.5, test.sided = ">")
bruceR::TTEST(df.pg.mean, "HOME_mean", test.value = 3.5, test.sided = "<")
result.ttest <- capture.output({
bruceR::TTEST(data=df.pg.mean,
y="HOME_mean",
test.value = 3.5,
test.sided = "=",
file = "./output/chp7/single_t.doc")
})
writeLines(result.ttest, "./output/chp7/single_t.md") # .md最整齐
result.ttest <- capture.output({
bruceR::TTEST(data=df.pg.mean,
y="ECR_mean",
x="sex")
})
writeLines(result.ttest, "./output/chp7/inde_t.md")
result.ttest <- capture.output({
bruceR::TTEST(data=df.pg.mean,
y = c("Temperature_t1",
"Temperature_t2"),
paired = T)  #是否为配对样本t检验？默认是FALSE
})
writeLines(result.ttest, "./output/chp7/pair_t.md")
WD <-  here::here()
df.match.raw <-  read.csv('./data/match/match_raw.csv',
header = T, sep=",", stringsAsFactors = FALSE)%>%
tidyr::separate(., col=Shape,into = c("Valence","Identity"),
sep = "(?<=moral|immoral)(?=Self|Other)")%>% #拆分单元格内字符串
dplyr::select(Sub,Valence,Identity,everything())%>%
dplyr::filter(ACC == 1) %>% #只选择回答正确的数据
dplyr::filter(RT > quantile(RT, 0.0015) & RT < quantile(RT, 0.9985)) %>% #remove outliers below and above 3rd sd
dplyr::mutate(RT = as.numeric(RT)) %>%
dplyr::mutate(across("ACC", as.factor)) %>%
dplyr::mutate(Valence = as.factor(Valence)) %>%
dplyr::mutate(Identity = as.factor(Identity)) %>%
dplyr::filter(!is.na(RT)) #剔除缺失值
df.match.mean <- df.match.raw %>%
dplyr::group_by(Sub, Match) %>%
dplyr::summarise(
n = n(),
rt_sd = sd(as.numeric(RT), na.rm = T),
rt_mean = mean(as.numeric(RT), na.rm = T),
acc_mean=mean(as.numeric(as.character(ACC)),na.rm=T)#对于factor数据，先转成character，再变成numeric
) %>%
dplyr::ungroup()
WD <-  here::here()
df.match.raw <-  read.csv('./data/match/match_raw.csv',
header = T, sep=",", stringsAsFactors = FALSE)%>%
tidyr::separate(., col=Shape,into = c("Valence","Identity"),
sep = "(?<=moral|immoral)(?=Self|Other)")%>% #拆分单元格内字符串
dplyr::select(Sub,Valence,Identity,everything())%>%
dplyr::filter(ACC == 1) %>% #只选择回答正确的数据
dplyr::filter(RT > quantile(RT, 0.0015) & RT < quantile(RT, 0.9985)) %>% #remove outliers below and above 3rd sd
dplyr::mutate(RT = as.numeric(RT)) %>%
dplyr::mutate(across("ACC", as.factor)) %>%
dplyr::mutate(Valence = as.factor(Valence)) %>%
dplyr::mutate(Identity = as.factor(Identity)) %>%
dplyr::filter(!is.na(RT)) #剔除缺失值
df.match.mean <- df.match.raw %>%
dplyr::group_by(Sub, Match) %>%
dplyr::summarise(
n = n(),
rt_sd = sd(as.numeric(RT), na.rm = T),
rt_mean = mean(as.numeric(RT), na.rm = T),
acc_mean=mean(as.numeric(as.character(ACC)),na.rm=T)#对于factor数据，先转成character，再变成numeric
) %>%
dplyr::ungroup()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # Wickham的数据整理的整套工具
pdf.options(height=10/2.54, width=10/2.54, family="GB1") # 注意：此设置要放在最后
install.packages("bruceR")
library(bruceR)
library(dplyr)
library(tidyr)
WD <-  here::here()
df.pg.raw <-  read.csv('./data/penguin/penguin_rawdata.csv',
header = T, sep=",", stringsAsFactors = FALSE)
df.pg.mean <- df.pg.raw %>%
dplyr::filter(sex > 0 & sex < 3) %>%
dplyr::mutate(ECR_mean = rowMeans(select(., starts_with("ECR")),na.rm = T),
HOME_mean = rowMeans(select(., starts_with("HOME")),na.rm = T),
sex=as.factor(sex)
) %>%
dplyr::select(sex, ECR_mean, HOME_mean, Temperature_t1,Temperature_t2)
bruceR::TTEST(df.pg.mean, "HOME_mean", test.value = 3.5, test.sided = ">")
bruceR::TTEST(df.pg.mean, "HOME_mean", test.value = 3.5, test.sided = "<")
result.ttest <- capture.output({
bruceR::TTEST(data=df.pg.mean,
y="HOME_mean",
test.value = 3.5,
test.sided = "=",
file = "./output/chp7/single_t.doc")
})
writeLines(result.ttest, "./output/chp7/single_t.md") # .md最整齐
result.ttest <- capture.output({
bruceR::TTEST(data=df.pg.mean,
y="ECR_mean",
x="sex")
})
writeLines(result.ttest, "./output/chp7/inde_t.md")
result.ttest <- capture.output({
bruceR::TTEST(data=df.pg.mean,
y = c("Temperature_t1",
"Temperature_t2"),
paired = T)  #是否为配对样本t检验？默认是FALSE
})
writeLines(result.ttest, "./output/chp7/pair_t.md")
WD <-  here::here()
df.match.raw <-  read.csv('./data/match/match_raw.csv',
header = T, sep=",", stringsAsFactors = FALSE)%>%
tidyr::separate(., col=Shape,into = c("Valence","Identity"),
sep = "(?<=moral|immoral)(?=Self|Other)")%>% #拆分单元格内字符串
dplyr::select(Sub,Valence,Identity,everything())%>%
dplyr::filter(ACC == 1) %>% #只选择回答正确的数据
dplyr::filter(RT > quantile(RT, 0.0015) & RT < quantile(RT, 0.9985)) %>% #remove outliers below and above 3rd sd
dplyr::mutate(RT = as.numeric(RT)) %>%
dplyr::mutate(across("ACC", as.factor)) %>%
dplyr::mutate(Valence = as.factor(Valence)) %>%
dplyr::mutate(Identity = as.factor(Identity)) %>%
dplyr::filter(!is.na(RT)) #剔除缺失值
DT::datatable(head(df.match.raw, 10),
fillContainer = TRUE, options = list(pageLength = 5))
#比较被试在匹配任务和不匹配任务上的反应时是否存在差异
#单因素被试内设计（长型数据）
result.anova <- capture.output({
df_within <- df.match.mean%>%
bruceR::MANOVA(subID="Sub",#被试id
dv="rt_mean",#因变量，因为是MANOVA，实际上因变量可以再后面设置很多个
within="Match") #设置条件，因素分析的条件
})
writeLines(result.anova, "./output/chp7/anova_1.md")
# 若不符合球形假设要加上：sph.correction = "GG"
WD <-  here::here()
df.match.raw <-  read.csv('./data/match/match_raw.csv',
header = T, sep=",", stringsAsFactors = FALSE)%>%
tidyr::separate(., col=Shape,into = c("Valence","Identity"),
sep = "(?<=moral|immoral)(?=Self|Other)")%>% #拆分单元格内字符串
dplyr::select(Sub,Valence,Identity,everything())%>%
dplyr::filter(ACC == 1) %>% #只选择回答正确的数据
dplyr::filter(RT > quantile(RT, 0.0015) & RT < quantile(RT, 0.9985)) %>% #remove outliers below and above 3rd sd
dplyr::mutate(RT = as.numeric(RT)) %>%
dplyr::mutate(across("ACC", as.factor)) %>%
dplyr::mutate(Valence = as.factor(Valence)) %>%
dplyr::mutate(Identity = as.factor(Identity)) %>%
dplyr::filter(!is.na(RT)) #剔除缺失值
df.match.mean <- df.match.raw %>%
dplyr::group_by(Sub, Match) %>%
dplyr::summarise(
n = n(),
rt_sd = sd(as.numeric(RT), na.rm = T),
rt_mean = mean(as.numeric(RT), na.rm = T),
acc_mean=mean(as.numeric(as.character(ACC)),na.rm=T)#对于factor数据，先转成character，再变成numeric
) %>%
dplyr::ungroup()
#比较被试在匹配任务和不匹配任务上的反应时是否存在差异
#单因素被试内设计（长型数据）
result.anova <- capture.output({
df_within <- df.match.mean%>%
bruceR::MANOVA(subID="Sub",#被试id
dv="rt_mean",#因变量，因为是MANOVA，实际上因变量可以再后面设置很多个
within="Match") #设置条件，因素分析的条件
})
writeLines(result.anova, "./output/chp7/anova_1.md")
# 若不符合球形假设要加上：sph.correction = "GG"
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # Wickham的数据整理的整套工具
pdf.options(height=10/2.54, width=10/2.54, family="GB1") # 注意：此设置要放在最后
install.packages("bruceR")
library(bruceR)
library(dplyr)
library(tidyr)
install.packages("bruceR")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # Wickham的数据整理的整套工具
pdf.options(height=10/2.54, width=10/2.54, family="GB1") # 注意：此设置要放在最后
install.packages("bruceR")
library(bruceR)
library(dplyr)
library(tidyr)
install.packages("bruceR")
install.packages("bruceR")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # Wickham的数据整理的整套工具
pdf.options(height=10/2.54, width=10/2.54, family="GB1") # 注意：此设置要放在最后
install.packages("bruceR")
library(bruceR)
library(dplyr)
library(tidyr)
install.packages("bruceR")
install.packages("bruceR")
library(bruceR)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # Wickham的数据整理的整套工具
pdf.options(height=10/2.54, width=10/2.54, family="GB1") # 注意：此设置要放在最后
install.packages("bruceR")
library(bruceR)
library(dplyr)
library(tidyr)
WD <-  here::here()
df.pg.raw <-  read.csv('./data/penguin/penguin_rawdata.csv',
header = T, sep=",", stringsAsFactors = FALSE)
df.pg.mean <- df.pg.raw %>%
dplyr::filter(sex > 0 & sex < 3) %>%
dplyr::mutate(ECR_mean = rowMeans(select(., starts_with("ECR")),na.rm = T),
HOME_mean = rowMeans(select(., starts_with("HOME")),na.rm = T),
sex=as.factor(sex)
) %>%
dplyr::select(sex, ECR_mean, HOME_mean, Temperature_t1,Temperature_t2)
bruceR::TTEST(df.pg.mean, "HOME_mean", test.value = 3.5, test.sided = ">")
bruceR::TTEST(df.pg.mean, "HOME_mean", test.value = 3.5, test.sided = "<")
result.ttest <- capture.output({
bruceR::TTEST(data=df.pg.mean,
y="HOME_mean",
test.value = 3.5,
test.sided = "=",
file = "./output/chp7/single_t.doc")
})
writeLines(result.ttest, "./output/chp7/single_t.md") # .md最整齐
result.ttest <- capture.output({
bruceR::TTEST(data=df.pg.mean,
y="ECR_mean",
x="sex")
})
writeLines(result.ttest, "./output/chp7/inde_t.md")
result.ttest <- capture.output({
bruceR::TTEST(data=df.pg.mean,
y = c("Temperature_t1",
"Temperature_t2"),
paired = T)  #是否为配对样本t检验？默认是FALSE
})
writeLines(result.ttest, "./output/chp7/pair_t.md")
df.match <-  read.csv('./data/match/match_raw.csv',
header = T, sep=",", stringsAsFactors = FALSE) %>%
# 拆分单元格内字符串
tidyr::separate(col=Shape,
into=c("Valence","Identity"),
sep="(?<=moral|immoral)(?=Self|Other)") %>%
dplyr::select(Sub, Valence, Identity, everything()) %>%
dplyr::filter(ACC == 1) %>%    # 只选择回答正确的数据
dplyr::filter(!is.na(RT)) %>%  # 剔除缺失值
# remove outliers below and above 3rd sd
dplyr::filter(RT > quantile(RT, 0.0015) & RT < quantile(RT, 0.9985)) %>%
dplyr::mutate(RT = as.numeric(RT)) %>%
dplyr::mutate(Valence = as.factor(Valence),
Identity = as.factor(Identity))
WD <-  here::here()
df.match.raw <-  read.csv('./data/match/match_raw.csv',
header = T, sep=",", stringsAsFactors = FALSE)%>%
tidyr::separate(., col=Shape,into = c("Valence","Identity"),
sep = "(?<=moral|immoral)(?=Self|Other)")%>% #拆分单元格内字符串
dplyr::select(Sub,Valence,Identity,everything())%>%
dplyr::filter(ACC == 1) %>% #只选择回答正确的数据
dplyr::filter(RT > quantile(RT, 0.0015) & RT < quantile(RT, 0.9985)) %>% #remove outliers below and above 3rd sd
dplyr::mutate(RT = as.numeric(RT)) %>%
dplyr::mutate(across("ACC", as.factor)) %>%
dplyr::mutate(Valence = as.factor(Valence)) %>%
dplyr::mutate(Identity = as.factor(Identity)) %>%
dplyr::filter(!is.na(RT)) #剔除缺失值
df.match.mean <- df.match.raw %>%
dplyr::group_by(Sub, Match) %>%
dplyr::summarise(
n = n(),
rt_sd = sd(as.numeric(RT), na.rm = T),
rt_mean = mean(as.numeric(RT), na.rm = T),
acc_mean=mean(as.numeric(as.character(ACC)),na.rm=T)#对于factor数据，先转成character，再变成numeric
) %>%
dplyr::ungroup()
#比较被试在匹配任务和不匹配任务上的反应时是否存在差异
#单因素被试内设计（长型数据）
result.anova <- capture.output({
df_within <- df.match.mean%>%
bruceR::MANOVA(subID="Sub",#被试id
dv="rt_mean",#因变量，因为是MANOVA，实际上因变量可以再后面设置很多个
within="Match") #设置条件，因素分析的条件
})
writeLines(result.anova, "./output/chp7/anova_1.md")
# 若不符合球形假设要加上：sph.correction = "GG"
df.match.mean <- df.match %>%
dplyr::group_by(Sub,Sex, Valence,Identity) %>%
dplyr::summarise(
n = n(),
rt_sd = sd(as.numeric(RT), na.rm = T),
rt_mean = mean(as.numeric(RT), na.rm = T)
) %>%
dplyr::ungroup()
df.match.within <- df.match.mean %>%
dplyr::select(-c(n, rt_sd)) %>%
dplyr::mutate(Valence = paste("A_", Valence, sep = ""),#将变量的名称进行修改转换，不生产新的变量
Identity = paste("B_", Identity, sep = "")) %>%
# 将morality和identity组合名称起来生成一个新的变量"Conds"
tidyr::unite("Conds", Valence:Identity, sep = "&",remove=TRUE) %>%
tidyr::pivot_wider(names_from = Conds,
values_from = rt_mean)
head(df.match.within)
#str(df.match.within)
#被试在不同身份(self vs other)与不同效价(moral vs moral)的条件组合下反应时是否存在差异）
result.anova <- capture.output({
res_rmANOVA_1 <- bruceR::MANOVA(data=df.match.within,
dvs="A_immoral&B_Other:A_moral&B_Self",
dvs.pattern="A_(.+)B_(.+)",#正则表达式
within=c("A_","B_"))#表示2个主条件
})
writeLines(result.anova, "./output/chp7/anova_2.md")
#被试在不同身份(self vs other)与不同效价(good vs bad)的条件组合下反应时是否存在差异）
#head(df.match.mean)
result.anova <- capture.output({
res_rmANOVA_2 <- bruceR::MANOVA(data=df.match.mean,
dv="rt_mean",
within=c("Valence","Identity"),
subID="Sub")
})
writeLines(result.anova, "./output/chp7/anova_3.md")
result.check <- capture.output({
sim_eff_1 <- res_rmANOVA_1 %>%
bruceR::EMMEANS("A_", by="B_")#简单效应分析
})
writeLines(result.check, "./output/chp7/check.md")
#sim_eff_1 <- res_rmANOVA_1 %>%
#EMMEANS("B_", by="A_")   和上一个同理，只是转换了不同的形式
library(bruceR)
library(dplyr)
library(tidyr)
bookdown::publish_book()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # Wickham的数据整理的整套工具
pdf.options(height=10/2.54, width=10/2.54, family="GB1") # 注意：此设置要放在最后
# 检查是否已安装 pacman
if (!requireNamespace("pacman", quietly = TRUE)) {
install.packages("pacman") }   # 如果未安装，则安装包
# 使用p_load来载入需要的包
pacman::p_load("tidyverse", "bruceR", "performance", "lavaan", "lavaanPlot")
df.pg.raw <-  read.csv('./data/penguin/penguin_rawdata_full.csv',
header = T, sep=",", stringsAsFactors = FALSE)
# 检查是否已安装 pacman
if (!requireNamespace("pacman", quietly = TRUE)) {
install.packages("pacman") }   # 如果未安装，则安装包
# 使用p_load来载入需要的包
pacman::p_load("tidyverse", "bruceR", "performance", "lavaan", "lavaanPlot")
df.pg.raw <-  read.csv('./data/penguin/penguin_rawdata_full.csv',
header = T, sep=",", stringsAsFactors = FALSE)
df.pg.raw <-  read.csv('./data/penguin/penguin_rawdata_full.csv',
header = T, sep=",", stringsAsFactors = FALSE)
snDivNames  <- c("SNI3" , "SNI5", "SNI7" , "SNI9" , "SNI11"  , "SNI13",  "SNI15", "SNI17","SNI18","SNI19",
"SNI21")
extrDivName <- c("SNI28","SNI29","SNI30","SNI31","SNI32")    # colnames of the extra groups
### get data for diversity
snDivData <- setNames(data.frame(matrix(ncol = length(snDivNames), nrow = nrow(df.pg.raw))), snDivNames)
### recode spouse/partner Q10 (spouse): 1-> 1; else ->0
snDivData$SNI1_r <- car::recode(df.pg.raw$SNI1,"1= 1; else = 0")
### re-code Q12 ~ Q30: NA -> 0; 0 -> 0; 1~10 -> 1
snDivData[,snDivNames] <- apply(df.pg.raw[,snDivNames],2,function(x) {x <- car::recode(x,"0 = 0; NA = 0; 1:10 = 1;"); x})
colnames(snDivData[,snDivNames]) <- paste(snDivNames,"div",  sep = "_")   # add suffix to the colnames
snDivData$SNIwork   <- snDivData$SNI17 + snDivData$SNI18                  # combine the diversity of work (SNI17, SNI18)
snDivData$SNIwork_r <- car::recode(snDivData$SNIwork,"0 = 0;1:10 = 1")
### re-code extra groups, 0/NA --> 0; more than 0 --> 1
extrDivData <- df.pg.raw[,extrDivName]  # Get extra data
### sum and recode the extra groups
extrDivData$sum <- rowSums(extrDivData)
snDivData$extrDiv_r <- car::recode(extrDivData$sum,"0 = 0; NA = 0; else = 1")
### combine the recoded variables
snDivNames_r <- c("SNI1_r","SNI3","SNI5","SNI7","SNI9","SNI11","SNI13","SNI15","SNIwork_r",
"SNI19","SNI21","extrDiv_r")
### get the social diveristy score
snDivData$SNdiversity   <- rowSums(snDivData[,snDivNames_r])
### save the social diversity index
df.pg.raw$socialdiversity <- snDivData$SNdiversity
rm(extrDivData, snDivData, extrDiv_r, snDivNames, snDivNames_r, extrDivName)
write.csv(df.pg.raw, "./data/penguin/penguin_rawdata_new.csv")
df.pg.raw <-  read.csv('./data/penguin/penguin_rawdata_new.csv',
header = T, sep=",", stringsAsFactors = FALSE) %>%
dplyr::select(., age, language, avgtemp,socialdiversity, DEQ,
starts_with("ALEX"),
starts_with("ECR"),
starts_with("HOME"),
starts_with("KAMF"),
starts_with("SNI"),
)
# 这些包含原始题目的数据集，将在SEM lavaan中直接使用
DT::datatable(head(df.pg.raw, 10),
fillContainer = TRUE, options = list(pageLength = 5))
bookdown::publish_book(name = NULL, account = NULL, server = NULL,
render = c("none", "local", "server"))
bookdown::publish_book(name = "R4PsyBook", account = NULL, server = NULL,
render = c("none", "local", "server"))
bookdown::publish_book(name = "R4PsyBook", account = NULL, server = NULL,
render = c("none", "local", "server"))
bookdown::render_book(input = "index.Rmd", "bookdown::gitbook")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # Wickham的数据整理的整套工具
pdf.options(height=10/2.54, width=10/2.54, family="GB1") # 注意：此设置要放在最后
# 检查是否已安装 pacman
if (!requireNamespace("pacman", quietly = TRUE)) {
install.packages("pacman") }   # 如果未安装，则安装包
# 使用p_load来载入需要的包
pacman::p_load("tidyverse", "bruceR", "performance", "lavaan", "lavaanPlot")
df.pg.raw <-  read.csv('./data/penguin/penguin_rawdata_full.csv',
header = T, sep=",", stringsAsFactors = FALSE)
snDivNames  <- c("SNI3" , "SNI5", "SNI7" , "SNI9" , "SNI11"  , "SNI13",  "SNI15", "SNI17","SNI18","SNI19",
"SNI21")
extrDivName <- c("SNI28","SNI29","SNI30","SNI31","SNI32")    # colnames of the extra groups
### get data for diversity
snDivData <- setNames(data.frame(matrix(ncol = length(snDivNames), nrow = nrow(df.pg.raw))), snDivNames)
### recode spouse/partner Q10 (spouse): 1-> 1; else ->0
snDivData$SNI1_r <- car::recode(df.pg.raw$SNI1,"1= 1; else = 0")
### re-code Q12 ~ Q30: NA -> 0; 0 -> 0; 1~10 -> 1
snDivData[,snDivNames] <- apply(df.pg.raw[,snDivNames],2,function(x) {x <- car::recode(x,"0 = 0; NA = 0; 1:10 = 1;"); x})
colnames(snDivData[,snDivNames]) <- paste(snDivNames,"div",  sep = "_")   # add suffix to the colnames
snDivData$SNIwork   <- snDivData$SNI17 + snDivData$SNI18                  # combine the diversity of work (SNI17, SNI18)
snDivData$SNIwork_r <- car::recode(snDivData$SNIwork,"0 = 0;1:10 = 1")
### re-code extra groups, 0/NA --> 0; more than 0 --> 1
extrDivData <- df.pg.raw[,extrDivName]  # Get extra data
### sum and recode the extra groups
extrDivData$sum <- rowSums(extrDivData)
snDivData$extrDiv_r <- car::recode(extrDivData$sum,"0 = 0; NA = 0; else = 1")
### combine the recoded variables
snDivNames_r <- c("SNI1_r","SNI3","SNI5","SNI7","SNI9","SNI11","SNI13","SNI15","SNIwork_r",
"SNI19","SNI21","extrDiv_r")
### get the social diveristy score
snDivData$SNdiversity   <- rowSums(snDivData[,snDivNames_r])
### save the social diversity index
df.pg.raw$socialdiversity <- snDivData$SNdiversity
rm(extrDivData, snDivData, extrDiv_r, snDivNames, snDivNames_r, extrDivName)
write.csv(df.pg.raw, "./data/penguin/penguin_rawdata_new.csv")
df.pg.raw <-  read.csv('./data/penguin/penguin_rawdata_new.csv',
header = T, sep=",", stringsAsFactors = FALSE) %>%
dplyr::select(., age, language, avgtemp,socialdiversity, DEQ,
starts_with("ALEX"),
starts_with("ECR"),
starts_with("HOME"),
starts_with("KAMF"),
starts_with("SNI"),
)
# 这些包含原始题目的数据集，将在SEM lavaan中直接使用
DT::datatable(head(df.pg.raw, 10),
fillContainer = TRUE, options = list(pageLength = 5))
# convert data to utf-8
df.pg.raw$SNI23 <- iconv(df.pg.raw$SNI23, to = "UTF-8")
DT::datatable(head(df.pg.raw, 10),
fillContainer = TRUE, options = list(pageLength = 5))
bookdown::render_book(input = "index.Rmd", "bookdown::gitbook")
bookdown::render_book(input = "index.Rmd", "bookdown::gitbook")
bookdown::render_book(input = "index.Rmd", "bookdown::gitbook")
bookdown::render_book(input = "index.Rmd", "bookdown::gitbook")
bookdown::publish_book(name = "R4PsyBook", account = NULL, server = NULL,  render = c("none", "local", "server"))
bookdown::render_book(input = "index.Rmd", "bookdown::gitbook")
bookdown::publish_book(name = "R4PsyBook", account = NULL, server = NULL,  render = c("none", "local", "server"))
